{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-12-05T10:42:34.410418Z","iopub.status.busy":"2023-12-05T10:42:34.409403Z","iopub.status.idle":"2023-12-05T10:42:34.428780Z","shell.execute_reply":"2023-12-05T10:42:34.427686Z","shell.execute_reply.started":"2023-12-05T10:42:34.410372Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-12-10 10:05:51.643819: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n","2023-12-10 10:05:53.833061: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-12-10 10:05:53.833180: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-12-10 10:05:54.149815: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-12-10 10:05:54.881617: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n","2023-12-10 10:05:54.882373: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-12-10 10:05:58.267741: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]}],"source":["#Import model\n","import pandas as pd\n","import numpy as np\n","import os\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import seaborn as sns\n","\n","from tqdm.notebook import tqdm\n","\n","from PIL import Image\n","\n","#import warnings\n","#warnings.filterwarnings('ignore')\n","\n","\n","from tensorflow.keras.utils import plot_model\n","\n","import tensorflow as tf\n","from keras.models import Sequential, Model\n","from keras.layers import Dense, Dropout, Conv2D, Flatten, MaxPooling2D, Input,BatchNormalization,Activation, GlobalAveragePooling2D, Add\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import MinMaxScaler\n","from keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.optimizers import Adam\n","\n","#Librairie to split dataset\n","from sklearn.model_selection import train_test_split \n","from sklearn.metrics import accuracy_score, mean_absolute_error\n","\n","#For model Xception\n","from tensorflow.keras.applications import Xception\n","\n","#For model VGG19\n","from tensorflow.keras.applications import VGG19  \n","\n","# For model ResNet152V2\n","from tensorflow.keras.applications import ResNet152V2 \n","\n","#For model InceptionResNetV2 \n","from tensorflow.keras.applications import InceptionResNetV2\n","\n","#For model MobileNetV2\n","from tensorflow.keras.applications import MobileNetV2\n","\n","#For model DenseNet201\n","from tensorflow.keras.applications import DenseNet201\n","\n","#For model NASNetLarge \n","from tensorflow.keras.applications import NASNetLarge \n","\n","#For model EfficientNetB7 \n","from tensorflow.keras.applications import EfficientNetB7 \n","\n","#For model EfficientNetV2L \n","from tensorflow.keras.applications import EfficientNetV2L \n","\n","#For model ConvNeXtXLarge\n","from tensorflow.keras.applications import ConvNeXtXLarge "]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-11-29T08:27:01.173186Z","iopub.status.busy":"2023-11-29T08:27:01.172120Z","iopub.status.idle":"2023-11-29T08:27:01.178761Z","shell.execute_reply":"2023-11-29T08:27:01.177865Z","shell.execute_reply.started":"2023-11-29T08:27:01.173137Z"},"trusted":true},"outputs":[],"source":["#Load the dataset\n","BASE_DIR = 'UTKFace/'"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-11-29T08:27:05.780255Z","iopub.status.busy":"2023-11-29T08:27:05.779825Z","iopub.status.idle":"2023-11-29T08:27:06.291536Z","shell.execute_reply":"2023-11-29T08:27:06.290428Z","shell.execute_reply.started":"2023-11-29T08:27:05.780223Z"},"trusted":true},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'https://www.kaggle.com/datasets/jangedoo/utkface-new/download?datasetVersionNumber=1'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m/workspaces/cnn_project_age_and_gender_by_Korka/final_project.ipynb Cell 3\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bspecial-couscous-65gw7g9p4jx2rgxp/workspaces/cnn_project_age_and_gender_by_Korka/final_project.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m age_labels \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bspecial-couscous-65gw7g9p4jx2rgxp/workspaces/cnn_project_age_and_gender_by_Korka/final_project.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m gender_labels \u001b[39m=\u001b[39m []\n\u001b[0;32m----> <a href='vscode-notebook-cell://codespaces%2Bspecial-couscous-65gw7g9p4jx2rgxp/workspaces/cnn_project_age_and_gender_by_Korka/final_project.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m filename \u001b[39min\u001b[39;00m tqdm(os\u001b[39m.\u001b[39;49mlistdir(BASE_DIR)):\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bspecial-couscous-65gw7g9p4jx2rgxp/workspaces/cnn_project_age_and_gender_by_Korka/final_project.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     image_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(BASE_DIR, filename)\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bspecial-couscous-65gw7g9p4jx2rgxp/workspaces/cnn_project_age_and_gender_by_Korka/final_project.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     temps \u001b[39m=\u001b[39m filename\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m)\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'https://www.kaggle.com/datasets/jangedoo/utkface-new/download?datasetVersionNumber=1'"]}],"source":["#label Age, gender and Ethnicity\n","images_paths = []\n","age_labels = []\n","gender_labels = []\n","\n","for filename in tqdm(os.listdir(BASE_DIR)):\n","    image_path = os.path.join(BASE_DIR, filename)\n","    temps = filename.split(\"_\")\n","    ages = int(temps[0])\n","    genders = int(temps[1])\n","    \n","    images_paths.append(image_path)\n","    age_labels.append(ages)\n","    gender_labels.append(genders)\n","    \n","    #print(images_paths)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T14:23:38.158796Z","iopub.status.busy":"2023-12-04T14:23:38.158259Z","iopub.status.idle":"2023-12-04T14:23:38.218447Z","shell.execute_reply":"2023-12-04T14:23:38.217271Z","shell.execute_reply.started":"2023-12-04T14:23:38.158751Z"},"trusted":true},"outputs":[],"source":["#transform the dataset to dataFrame\n","data = pd.DataFrame()\n","\n","data['image'], data['age'], data['gender'] = images_paths, age_labels, gender_labels\n","data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T14:23:45.030491Z","iopub.status.busy":"2023-12-04T14:23:45.029771Z","iopub.status.idle":"2023-12-04T14:23:45.038393Z","shell.execute_reply":"2023-12-04T14:23:45.037069Z","shell.execute_reply.started":"2023-12-04T14:23:45.030442Z"},"trusted":true},"outputs":[],"source":["data.size"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T14:23:47.925087Z","iopub.status.busy":"2023-12-04T14:23:47.924682Z","iopub.status.idle":"2023-12-04T14:23:47.929071Z","shell.execute_reply":"2023-12-04T14:23:47.928151Z","shell.execute_reply.started":"2023-12-04T14:23:47.925058Z"},"trusted":true},"outputs":[],"source":["#map label for gender\n","gender_dic = {0: 'Male', 1:'Femel'}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T14:24:00.189924Z","iopub.status.busy":"2023-12-04T14:24:00.189539Z","iopub.status.idle":"2023-12-04T14:24:00.512798Z","shell.execute_reply":"2023-12-04T14:24:00.511430Z","shell.execute_reply.started":"2023-12-04T14:24:00.189895Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from PIL import Image   \n","\n"," \n","image_path = data['image'][130]\n","\n","# Display the image\n","img = Image.open(image_path)\n","plt.imshow(img)\n","\n","# Extract image name and extension\n","image_name = image_path.split('/')[-1].split('.')[0]  # Adjust the path delimiter if needed\n","image_extension = image_path.split('.')[-1]\n","\n","# Add text to display image name and extension\n","text = f\"{image_name}.{image_extension}\"\n","plt.text(0.5, -0.1, text, ha='center', va='center', transform=plt.gca().transAxes, fontsize=12, color='black')\n","\n","# Show the plot\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T14:24:13.173928Z","iopub.status.busy":"2023-12-04T14:24:13.173495Z","iopub.status.idle":"2023-12-04T14:24:13.662188Z","shell.execute_reply":"2023-12-04T14:24:13.661261Z","shell.execute_reply.started":"2023-12-04T14:24:13.173892Z"},"trusted":true},"outputs":[],"source":["#Diplay the distribution of age and also of the gender \n","\n","# Plot the distribution of age using a histogram\n","plt.figure(figsize=(10, 5))\n"," \n","sns.histplot(data=data, x='age', bins=20, kde=True)\n","plt.title('Distribution of Age')\n"," \n","\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-28T15:58:58.757128Z","iopub.status.busy":"2023-11-28T15:58:58.756822Z","iopub.status.idle":"2023-11-28T15:58:58.762320Z","shell.execute_reply":"2023-11-28T15:58:58.761317Z","shell.execute_reply.started":"2023-11-28T15:58:58.757101Z"},"trusted":true},"outputs":[],"source":["#scalar the age distribution\n","\n","# Create an instance of MinMaxScaler\n","#scaler = MinMaxScaler()\n","# Reshape the 'age' column to a 2D array\n","#new_ages = data['age'].values.reshape(-1, 1)\n","# Fit the scaler to the 'age' column and compute the minimum and maximum values\n","#scaler.fit(new_ages)\n","# Transform the 'age' data using the computed minimum and maximum values\n","#scaled_age = scaler.transform(new_ages)\n","\n","# Replace the original 'age' column with the scaled values\n","#data['age'] = scaled_age\n","\n","# Print the first few rows of the modified dataset\n","#print(data.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-28T15:58:58.766641Z","iopub.status.busy":"2023-11-28T15:58:58.766353Z","iopub.status.idle":"2023-11-28T15:58:58.773834Z","shell.execute_reply":"2023-11-28T15:58:58.772803Z","shell.execute_reply.started":"2023-11-28T15:58:58.766617Z"},"trusted":true},"outputs":[],"source":["# Plot the distribution of age after scaler\n","#plt.figure(figsize=(10, 5))\n"," \n","#sns.histplot(data=data, x='age', bins=20, kde=True)\n","#plt.title('Distribution of Age After scaled age')\n"," \n","\n","#plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T14:24:22.160960Z","iopub.status.busy":"2023-12-04T14:24:22.160559Z","iopub.status.idle":"2023-12-04T14:24:22.374299Z","shell.execute_reply":"2023-12-04T14:24:22.373402Z","shell.execute_reply.started":"2023-12-04T14:24:22.160928Z"},"trusted":true},"outputs":[],"source":["# Plot the distribution of gender using a count plot\n"," \n","\n","plt.figure(figsize=(10, 5))\n","ax = sns.countplot(data=data, x='gender', color='gray')\n","plt.title('Distribution of Gender')\n","\n","# Add count numbers on top of the bars\n","for p in ax.patches:\n","    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2, p.get_height()), ha='center', va='bottom')\n","\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T14:24:33.958127Z","iopub.status.busy":"2023-12-04T14:24:33.957729Z","iopub.status.idle":"2023-12-04T14:24:38.051972Z","shell.execute_reply":"2023-12-04T14:24:38.048740Z","shell.execute_reply.started":"2023-12-04T14:24:33.958097Z"},"trusted":true},"outputs":[],"source":["# Assuming gender_dict is a dictionary that maps gender codes (0 and 1) to gender labels ('Female' and 'Male')\n","\n","# to display grid of images\n","plt.figure(figsize=(20, 20))\n","files = data.iloc[0:25]\n","\n","# Filter data to get only the younger individuals\n","#files_younger = data[data['age'] < 30].iloc[0:25]\n","\n","for index, file, age, gender in files.itertuples():\n","    plt.subplot(5, 5, index+1)\n","    img =  Image.open(file)\n","    img = np.array(img)\n","    plt.imshow(img)\n","    plt.title(f\"Age: {age} Gender: {gender_dic[gender]}\")\n","    plt.axis('off')\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T14:25:46.251303Z","iopub.status.busy":"2023-12-04T14:25:46.250889Z","iopub.status.idle":"2023-12-04T14:25:46.259473Z","shell.execute_reply":"2023-12-04T14:25:46.258271Z","shell.execute_reply.started":"2023-12-04T14:25:46.251271Z"},"trusted":true},"outputs":[],"source":["def extract_features(images):\n","    features = []\n","    for image in tqdm(images):\n","        img = Image.open(image).convert('L')  # Convert to grayscale\n","        img = img.resize((128, 128), Image.LANCZOS)  # Use LANCZOS for resizing\n","        features.append(np.array(img))  # Convert the image to a NumPy array\n","\n","    # Check the shapes of the images in the features list\n","    shapes = set(img.shape for img in features)\n","    if len(shapes) > 1:\n","        raise ValueError(\"Images have different sizes or shapes.\")\n","\n","    features = np.array(features)\n","    # Reshape the features array to add the channel dimension (1 for grayscale)\n","    features = features.reshape(len(features), 128, 128, 1)\n","    return features"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T14:25:51.132942Z","iopub.status.busy":"2023-12-04T14:25:51.132516Z","iopub.status.idle":"2023-12-04T14:26:34.599081Z","shell.execute_reply":"2023-12-04T14:26:34.597865Z","shell.execute_reply.started":"2023-12-04T14:25:51.132911Z"},"trusted":true},"outputs":[],"source":["# Assuming 'data' is your DataFrame containing image paths in the 'image' column\n","Extractions = extract_features(data['image'])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T14:26:46.632132Z","iopub.status.busy":"2023-12-04T14:26:46.631728Z","iopub.status.idle":"2023-12-04T14:26:46.639408Z","shell.execute_reply":"2023-12-04T14:26:46.638288Z","shell.execute_reply.started":"2023-12-04T14:26:46.632101Z"},"trusted":true},"outputs":[],"source":["Extractions.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T14:26:50.272844Z","iopub.status.busy":"2023-12-04T14:26:50.272449Z","iopub.status.idle":"2023-12-04T14:26:51.642616Z","shell.execute_reply":"2023-12-04T14:26:51.641559Z","shell.execute_reply.started":"2023-12-04T14:26:50.272814Z"},"trusted":true},"outputs":[],"source":["#Normalize the extraction\n","Extractions = Extractions /255.0"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T14:26:53.913592Z","iopub.status.busy":"2023-12-04T14:26:53.913179Z","iopub.status.idle":"2023-12-04T14:26:53.919956Z","shell.execute_reply":"2023-12-04T14:26:53.917926Z","shell.execute_reply.started":"2023-12-04T14:26:53.913551Z"},"trusted":true},"outputs":[],"source":["y_gender = np.array(data['gender'])\n","y_age = np.array(data['age'])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T14:27:02.007888Z","iopub.status.busy":"2023-12-04T14:27:02.007091Z","iopub.status.idle":"2023-12-04T14:27:02.013489Z","shell.execute_reply":"2023-12-04T14:27:02.011845Z","shell.execute_reply.started":"2023-12-04T14:27:02.007852Z"},"trusted":true},"outputs":[],"source":["input_shape = (128, 128, 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T14:27:04.950455Z","iopub.status.busy":"2023-12-04T14:27:04.950017Z","iopub.status.idle":"2023-12-04T14:27:06.151982Z","shell.execute_reply":"2023-12-04T14:27:06.150724Z","shell.execute_reply.started":"2023-12-04T14:27:04.950420Z"},"trusted":true},"outputs":[],"source":["\n","# Split the dataset into training and validation sets\n","X_train, X_val, y_gender_train, y_gender_val, y_age_train, y_age_val = train_test_split(\n","    Extractions, y_gender, y_age, test_size=0.2, random_state=42)\n","\n","# Now, you have:\n","# - X_train: Training data\n","# - X_val: Validation data\n","# - y_gender_train: Training labels for gender\n","# - y_gender_val: Validation labels for gender\n","# - y_age_train: Training labels for age\n","# - y_age_val: Validation labels for age"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T14:27:12.941979Z","iopub.status.busy":"2023-12-04T14:27:12.941593Z","iopub.status.idle":"2023-12-04T14:27:16.300301Z","shell.execute_reply":"2023-12-04T14:27:16.299023Z","shell.execute_reply.started":"2023-12-04T14:27:12.941949Z"},"trusted":true},"outputs":[],"source":["#create Xception model\n","\n","input_shape_xception = input_shape\n","\n","# Load the Xception model pre-trained on ImageNet data\n","base_model = Xception(weights=None, include_top=False, input_shape=input_shape_xception)\n","\n","# Specify the local path to the Xception weights file\n","weights_path_Xception = '../input/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5'\n","\n","# Load weights locally\n","#base_model.load_weights(weights_path_Xception)\n","base_model.load_weights(weights_path_Xception, by_name=True)\n","\n","\n","# Set the convolutional base to be non-trainable (freeze the weights)\n","base_model.trainable = False\n","# summarize the base model architecture\n","base_model.summary()\n","print(\"****************************************************************\")\n","# Input layer\n","input_layer = Input(shape=input_shape_xception)\n","\n","\n","# Pass through Xception base model\n","inputs = base_model(input_layer)\n","\n","# Add custom convolutional layers with reduced downsampling\n","conv_1 = Conv2D(32, kernel_size=(3, 3), activation='relu')(inputs)\n","maxp_1 = MaxPooling2D(pool_size=(1, 1))(conv_1)\n","conv_2 = Conv2D(64, kernel_size=(1, 1), activation='relu')(maxp_1)\n","maxp_2 = MaxPooling2D(pool_size=(1, 1))(conv_2)\n","conv_3 = Conv2D(128, kernel_size=(1, 1), activation='relu')(maxp_2)\n","maxp_3 = MaxPooling2D(pool_size=(1, 1))(conv_3)\n","conv_4 = Conv2D(256, kernel_size=(1, 1), activation='relu')(maxp_3)\n","maxp_4 = MaxPooling2D(pool_size=(1, 1))(conv_4)\n","\n","# Flatten and add custom dense layers\n","flatten = Flatten()(maxp_4)\n","dense_1 = Dense(256, activation=\"relu\")(flatten)\n","dropout_1 = Dropout(0.3)(dense_1)\n","\n","# Output layer for gender prediction\n","output_gender = Dense(1, activation='sigmoid', name='output_gender')(dropout_1)\n","\n","# Output layer for age prediction (using linear activation for regression)\n","output_age = Dense(1, activation='linear', name='output_age')(dropout_1)\n","\n","# Create the Xception model with custom layers\n","xception_model = Model(inputs=input_layer, outputs=[output_gender, output_age])\n","\n","# Print a summary of the model architecture\n","xception_model.summary()\n","\n","# Compile the model\n","xception_model.compile(optimizer=Adam(),\n","                               loss=['binary_crossentropy', 'mean_absolute_error'],\n","                               metrics=['accuracy'])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T14:27:29.107708Z","iopub.status.busy":"2023-12-04T14:27:29.107104Z","iopub.status.idle":"2023-12-04T14:27:29.411730Z","shell.execute_reply":"2023-12-04T14:27:29.410809Z","shell.execute_reply.started":"2023-12-04T14:27:29.107652Z"},"trusted":true},"outputs":[],"source":["# plot the Xception model  \n","plot_model(xception_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T14:27:38.548366Z","iopub.status.busy":"2023-12-04T14:27:38.547904Z","iopub.status.idle":"2023-12-04T16:40:35.165558Z","shell.execute_reply":"2023-12-04T16:40:35.164152Z","shell.execute_reply.started":"2023-12-04T14:27:38.548314Z"},"trusted":true},"outputs":[],"source":["# Train the Xception model  \n","history1 = xception_model.fit(x=X_train, y=[y_gender_train, y_age_train], batch_size=32, epochs=10, validation_data=(X_val, [y_gender_val, y_age_val]))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T16:47:05.615935Z","iopub.status.busy":"2023-12-04T16:47:05.615483Z","iopub.status.idle":"2023-12-04T16:47:06.391085Z","shell.execute_reply":"2023-12-04T16:47:06.389823Z","shell.execute_reply.started":"2023-12-04T16:47:05.615903Z"},"trusted":true},"outputs":[],"source":["##Plot the Results\n","# plot results for gender\n","acc = history1.history['output_gender_accuracy']\n","val_acc = history1.history['val_output_gender_accuracy']\n","epochs = range(len(acc))\n","\n","plt.plot(epochs, acc, 'b', label='Training Accuracy')\n","plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n","plt.title('Accuracy Graph')\n","plt.legend()\n","plt.figure()\n","\n","print(\"-----------------------------------------------------------------------------------------\")\n","# plot results for gender\n","loss = history1.history['output_gender_loss']\n","val_loss = history1.history['val_output_gender_loss']\n","\n","plt.plot(epochs, loss, 'b', label='Training Loss')\n","plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n","plt.title('Loss Graph')\n","plt.legend()\n","plt.show()\n","\n","print(\"-----------------------------------------------------------------------------------------\")\n","# plot results for age\n","loss = history1.history['output_age_loss']\n","val_loss = history1.history['val_output_age_loss']\n","epochs = range(len(loss))\n","\n","plt.plot(epochs, loss, 'b', label='Training Loss')\n","plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n","plt.title('Loss Graph')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T16:47:16.837453Z","iopub.status.busy":"2023-12-04T16:47:16.837026Z","iopub.status.idle":"2023-12-04T16:47:18.070910Z","shell.execute_reply":"2023-12-04T16:47:18.069343Z","shell.execute_reply.started":"2023-12-04T16:47:16.837420Z"},"trusted":true},"outputs":[],"source":["#The prediction with xception model \n","##Test 1\n","#Prediction with Test Data\n","image_index = 100\n","print(\"Original Gender:\", gender_dic[y_gender[image_index]], \"Original Age:\", y_age[image_index])\n","# predict from model\n","pred = xception_model.predict(Extractions[image_index].reshape(1, 128, 128, 1))\n","pred_gender = gender_dic[round(pred[0][0][0])]\n","pred_age = round(pred[1][0][0])\n","print(\"Predicted Gender:\", pred_gender, \"Predicted Age:\", pred_age)\n","plt.axis('off')\n","plt.imshow(Extractions[image_index].reshape(128, 128), cmap='gray');"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T16:47:23.987177Z","iopub.status.busy":"2023-12-04T16:47:23.986761Z","iopub.status.idle":"2023-12-04T16:47:24.291443Z","shell.execute_reply":"2023-12-04T16:47:24.289545Z","shell.execute_reply.started":"2023-12-04T16:47:23.987143Z"},"trusted":true},"outputs":[],"source":["##Test 2\n","#Prediction with Test Data\n","image_index = 980\n","print(\"Original Gender:\", gender_dic[y_gender[image_index]], \"Original Age:\", y_age[image_index])\n","# predict from model\n","pred = xception_model.predict(Extractions[image_index].reshape(1, 128, 128, 1))\n","pred_gender = gender_dic[round(pred[0][0][0])]\n","pred_age = round(pred[1][0][0])\n","print(\"Predicted Gender:\", pred_gender, \"Predicted Age:\", pred_age)\n","plt.axis('off')\n","plt.imshow(Extractions[image_index].reshape(128, 128), cmap='gray');\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T16:47:32.138974Z","iopub.status.busy":"2023-12-04T16:47:32.138501Z","iopub.status.idle":"2023-12-04T16:47:32.459278Z","shell.execute_reply":"2023-12-04T16:47:32.457702Z","shell.execute_reply.started":"2023-12-04T16:47:32.138941Z"},"trusted":true},"outputs":[],"source":["##Test 3\n","#Prediction with Test Data\n","image_index = 666\n","print(\"Original Gender:\", gender_dic[y_gender[image_index]], \"Original Age:\", y_age[image_index])\n","# predict from model\n","pred = xception_model.predict(Extractions[image_index].reshape(1, 128, 128, 1))\n","pred_gender = gender_dic[round(pred[0][0][0])]\n","pred_age = round(pred[1][0][0])\n","print(\"Predicted Gender:\", pred_gender, \"Predicted Age:\", pred_age)\n","plt.axis('off')\n","plt.imshow(Extractions[image_index].reshape(128, 128), cmap='gray');"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T16:47:43.351553Z","iopub.status.busy":"2023-12-04T16:47:43.350409Z","iopub.status.idle":"2023-12-04T16:47:45.305186Z","shell.execute_reply":"2023-12-04T16:47:45.303930Z","shell.execute_reply.started":"2023-12-04T16:47:43.351517Z"},"trusted":true},"outputs":[],"source":["#Create a VGG16 model\n"," \n","input_shape_vgg19 = input_shape\n","\n","# Load the VGG19 model pre-trained on ImageNet data\n","base_model = VGG19(weights=None, include_top=False, input_shape=input_shape_vgg19)\n","\n","# Specify the local path to the VGG19 weights file\n","weights_path_VGG19 = '../input/vgg19-weights-tf-dim-ordering-tf-kernels-notop-h5/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5'\n","\n","# Load weights locally\n","base_model.load_weights(weights_path_VGG19, by_name=True, skip_mismatch=True)\n","# Set the convolutional base to be non-trainable (freeze the weights)\n","base_model.trainable = False\n","# Let's take a look at the base model architecture\n","base_model.summary()\n","print(\"****************************************************************\")\n","\n","\n","\n","# Input layer\n","input_layer = Input(shape=input_shape_vgg19)\n"," \n","\n","# Pass through VGG19 base model\n","inputs = base_model(input_layer)\n","\n","# Add custom convolutional layers with reduced downsampling\n","conv_1 = Conv2D(32, kernel_size=(3, 3), activation='relu')(inputs)\n","maxp_1 = MaxPooling2D(pool_size=(1, 1))(conv_1)\n","conv_2 = Conv2D(64, kernel_size=(1, 1), activation='relu')(maxp_1)\n","maxp_2 = MaxPooling2D(pool_size=(1, 1))(conv_2)\n","conv_3 = Conv2D(128, kernel_size=(1, 1), activation='relu')(maxp_2)\n","maxp_3 = MaxPooling2D(pool_size=(1, 1))(conv_3)\n","conv_4 = Conv2D(256, kernel_size=(1, 1), activation='relu')(maxp_3)\n","maxp_4 = MaxPooling2D(pool_size=(1, 1))(conv_4)\n","\n","# Flatten and add custom dense layers\n","flatten = Flatten()(maxp_4)\n","dense_1 = Dense(256, activation=\"relu\")(flatten)\n","dropout_1 = Dropout(0.3)(dense_1)\n","\n","# Output layer for gender prediction\n","output_gender = Dense(1, activation='sigmoid', name='output_gender')(dropout_1)\n","\n","# Output layer for age prediction (using linear activation for regression)\n","output_age = Dense(1, activation='linear', name='output_age')(dropout_1)\n","\n","# Create the VGG19 model with custom layers\n","vgg19_model = Model(inputs=input_layer, outputs=[output_gender, output_age])\n","\n","# Print a summary of the model architecture\n","vgg19_model.summary()\n","\n","# Compile the model\n","vgg19_model.compile(optimizer=Adam(),\n","                            loss=['binary_crossentropy', 'mean_absolute_error'],\n","                            metrics=['accuracy'])\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-04T16:47:52.359182Z","iopub.status.busy":"2023-12-04T16:47:52.358742Z","iopub.status.idle":"2023-12-04T16:47:52.483768Z","shell.execute_reply":"2023-12-04T16:47:52.482650Z","shell.execute_reply.started":"2023-12-04T16:47:52.359148Z"},"trusted":true},"outputs":[],"source":["# plot the vgg19_model model  \n","plot_model(vgg19_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Train the Xception model  \n","history2 = vgg19_model.fit(x=X_train, y=[y_gender_train, y_age_train], batch_size=32, epochs=10, validation_data=(X_val, [y_gender_val, y_age_val]))\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["##Plot the Results\n","# plot results for gender\n","acc = history2.history['output_gender_accuracy']\n","val_acc = history2.history['val_output_gender_accuracy']\n","epochs = range(len(acc))\n","\n","plt.plot(epochs, acc, 'b', label='Training Accuracy')\n","plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n","plt.title('Accuracy Graph')\n","plt.legend()\n","plt.figure()\n","\n","print(\"-----------------------------------------------------------------------------------------\")\n","# plot results for gender\n","loss = history2.history['output_gender_loss']\n","val_loss = history2.history['val_output_gender_loss']\n","\n","plt.plot(epochs, loss, 'b', label='Training Loss')\n","plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n","plt.title('Loss Graph')\n","plt.legend()\n","plt.show()\n","\n","print(\"-----------------------------------------------------------------------------------------\")\n","# plot results for age\n","loss = history2.history['output_age_loss']\n","val_loss = history2.history['val_output_age_loss']\n","epochs = range(len(loss))\n","\n","plt.plot(epochs, loss, 'b', label='Training Loss')\n","plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n","plt.title('Loss Graph')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#The prediction with xception model \n","##Test 1\n","#Prediction with Test Data\n","image_index = 100\n","print(\"Original Gender:\", gender_dic[y_gender[image_index]], \"Original Age:\", y_age[image_index])\n","# predict from model\n","pred = vgg19_model.predict(Extractions[image_index].reshape(1, 128, 128, 1))\n","pred_gender = gender_dic[round(pred[0][0][0])]\n","pred_age = round(pred[1][0][0])\n","print(\"Predicted Gender:\", pred_gender, \"Predicted Age:\", pred_age)\n","plt.axis('off')\n","plt.imshow(Extractions[image_index].reshape(128, 128), cmap='gray');\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#The prediction with xception model \n","##Test 1\n","#Prediction with Test Data\n","image_index = 980\n","print(\"Original Gender:\", gender_dic[y_gender[image_index]], \"Original Age:\", y_age[image_index])\n","# predict from model\n","pred = vgg19_model.predict(Extractions[image_index].reshape(1, 128, 128, 1))\n","pred_gender = gender_dic[round(pred[0][0][0])]\n","pred_age = round(pred[1][0][0])\n","print(\"Predicted Gender:\", pred_gender, \"Predicted Age:\", pred_age)\n","plt.axis('off')\n","plt.imshow(Extractions[image_index].reshape(128, 128), cmap='gray');\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#The prediction with xception model \n","##Test 3\n","#Prediction with Test Data\n","image_index = 666\n","print(\"Original Gender:\", gender_dic[y_gender[image_index]], \"Original Age:\", y_age[image_index])\n","# predict from model\n","pred = vgg19_model.predict(Extractions[image_index].reshape(1, 128, 128, 1))\n","pred_gender = gender_dic[round(pred[0][0][0])]\n","pred_age = round(pred[1][0][0])\n","print(\"Predicted Gender:\", pred_gender, \"Predicted Age:\", pred_age)\n","plt.axis('off')\n","plt.imshow(Extractions[image_index].reshape(128, 128), cmap='gray');\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#create a ResNet152V2\n","\n","# Assuming your input_shape is (224, 224, 3) for ResNet152V2\n","input_shape_resnet152v2 = (224, 224, 3)\n","\n","# Load the ResNet152V2 model pre-trained on ImageNet data\n","base_model = ResNet152V2(weights=None, include_top=False, input_shape=input_shape_resnet152v2)\n","\n","# Specify the local path to the ResNet152V2 weights file\n","weights_path_restNet = '../input/resnet152v2/resnet152v2_weights_tf_dim_ordering_tf_kernels_notop.h5'\n","\n","# Load weights locally\n","base_model.load_weights(weights_path_restNet)\n","\n","# Set the convolutional base to be non-trainable (freeze the weights)\n","base_model.trainable = False\n","# summarize the base model architecture\n","base_model.summary()\n","print(\"****************************************************************\")\n","# Input layer\n","input_layer = Input(shape=input_shape_resnet152v2)\n"," \n","# Pass through ResNet152V2 base model\n","output = base_model(input_layer)\n","\n","# Add custom convolutional layers with reduced downsampling\n","conv_1 = Conv2D(32, kernel_size=(3, 3), activation=\"relu\")(output)\n","maxp_1 = MaxPooling2D(pool_size=(1, 1))(conv_1)\n","\n","conv_2 = Conv2D(64, kernel_size=(3, 3), activation=\"relu\")(maxp_1)\n","maxp_2 = MaxPooling2D(pool_size=(1, 1))(conv_2)\n","\n","conv_3 = Conv2D(128, kernel_size=(3, 3), activation=\"relu\")(maxp_2)\n","maxp_3 = MaxPooling2D(pool_size=(1, 1))(conv_3)\n","\n","conv_4 = Conv2D(160, kernel_size=(1, 1), activation=\"relu\")(maxp_3)\n","\n","# Flatten and add custom dense layers\n","flatten = Flatten()(conv_4)\n","dense_1 = Dense(256, activation=\"relu\")(flatten)\n","dropout_1 = Dropout(0.3)(dense_1)\n","\n","# Output layer for gender prediction\n","output_gender = Dense(1, activation='sigmoid', name='output_gender')(dropout_1)\n","\n","# Output layer for age prediction (using linear activation for regression)\n","output_age = Dense(1, activation='linear', name='output_age')(dropout_1)\n","\n","# Create the ResNet152V2 model with custom layers\n","resnet152v2_model = Model(inputs=input_layer, outputs=[output_gender, output_age])\n","\n","# Print a summary of the model architecture\n","resnet152v2_model.summary()\n","\n","# Compile the model\n","resnet152v2_model.compile(optimizer=Adam(),\n","                                  loss=['binary_crossentropy', 'mean_absolute_error'],\n","                                  metrics=['accuracy'])\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# plot the resnet152v2 model  \n","plot_model(resnet152v2_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Train the Xception model  \n","history3 = resnet152v2_model.fit(x=X_train, y=[y_gender_train, y_age_train], batch_size=32, epochs=10, validation_data=(X_val, [y_gender_val, y_age_val]))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["##Plot the Results\n","# plot results for gender\n","acc = history3.history['output_gender_accuracy']\n","val_acc = history3.history['val_output_gender_accuracy']\n","epochs = range(len(acc))\n","\n","plt.plot(epochs, acc, 'b', label='Training Accuracy')\n","plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n","plt.title('Accuracy Graph')\n","plt.legend()\n","plt.figure()\n","\n","print(\"-----------------------------------------------------------------------------------------\")\n","# plot results for gender\n","loss = history3.history['output_gender_loss']\n","val_loss = history3.history['val_output_gender_loss']\n","\n","plt.plot(epochs, loss, 'b', label='Training Loss')\n","plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n","plt.title('Loss Graph')\n","plt.legend()\n","plt.show()\n","\n","print(\"-----------------------------------------------------------------------------------------\")\n","# plot results for age\n","loss = history3.history['output_age_loss']\n","val_loss = history3.history['val_output_age_loss']\n","epochs = range(len(loss))\n","\n","plt.plot(epochs, loss, 'b', label='Training Loss')\n","plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n","plt.title('Loss Graph')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Create  InceptionResNetV2 model\n","\n","# Assuming your input_shape is (299, 299, 3) for InceptionResNetV2\n","input_shape_inception = (299, 299, 3)\n","\n","# Load the InceptionResNetV2 model pre-trained on ImageNet data\n","base_model = InceptionResNetV2(weights=None, include_top=False, input_shape=input_shape_inception)\n","\n","# Specify the local path to the InceptionResNetV2 weights file\n","weights_path_InceptionResNetV2 = '../input/inception-resnet-v2-weights/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5'\n","\n","# Load weights locally\n","base_model.load_weights(weights_path_InceptionResNetV2)\n","\n","# Set the convolutional base to be non-trainable (freeze the weights)\n","base_model.trainable = False\n","# summarize the base model architecture\n","base_model.summary()\n","print(\"****************************************************************\")\n","# Input layer\n","input_layer = Input(shape=input_shape_inception)\n"," \n","# Pass through InceptionResNetV2 base model\n","output = base_model(input_layer)\n","\n","# Add custom convolutional layers with reduced downsampling\n","conv_1 = Conv2D(32, kernel_size=(3, 3), activation=\"relu\")(output)\n","maxp_1 = MaxPooling2D(pool_size=(1, 1))(conv_1)\n","\n","conv_2 = Conv2D(64, kernel_size=(1, 1), activation=\"relu\")(maxp_1)  # Reduced the kernel size\n","maxp_2 = MaxPooling2D(pool_size=(1, 1))(conv_2)\n","\n","conv_3 = Conv2D(128, kernel_size=(1, 1), activation=\"relu\")(maxp_2)  # Reduced the kernel size\n","\n","maxp_3 = MaxPooling2D(pool_size=(2, 2))(conv_3)\n","\n","conv_4 = Conv2D(160, kernel_size=(1, 1), activation=\"relu\")(maxp_3)\n","\n","# Flatten and add custom dense layers\n","flatten = Flatten()(conv_4)\n","dense_1 = Dense(256, activation=\"relu\")(flatten)\n","dropout_1 = Dropout(0.3)(dense_1)\n","\n","# Output layer for gender prediction\n","output_gender = Dense(1, activation='sigmoid', name='output_gender')(dropout_1)\n","\n","# Output layer for age prediction (using linear activation for regression)\n","output_age = Dense(1, activation='linear', name='output_age')(dropout_1)\n","\n","# Create the InceptionResNetV2 model with custom layers\n","inception_model = Model(inputs=input_layer, outputs=[output_gender, output_age])\n","\n","# Print a summary of the model architecture\n","inception_model.summary()\n","\n","# Compile the model\n","inception_model.compile(optimizer=Adam(),\n","                               loss=['binary_crossentropy', 'mean_absolute_error'],\n","                               metrics=['accuracy'])\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# plot the inception model  \n","plot_model(inception_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Train the Xception model  \n","history4 = plot_model.fit(x=X_train, y=[y_gender_train, y_age_train], batch_size=32, epochs=10, validation_data=(X_val, [y_gender_val, y_age_val]))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["##Plot the Results\n","# plot results for gender\n","acc = history4.history['output_gender_accuracy']\n","val_acc = history4.history['val_output_gender_accuracy']\n","epochs = range(len(acc))\n","\n","plt.plot(epochs, acc, 'b', label='Training Accuracy')\n","plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n","plt.title('Accuracy Graph')\n","plt.legend()\n","plt.figure()\n","\n","print(\"-----------------------------------------------------------------------------------------\")\n","# plot results for gender\n","loss = history4.history['output_gender_loss']\n","val_loss = history4.history['val_output_gender_loss']\n","\n","plt.plot(epochs, loss, 'b', label='Training Loss')\n","plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n","plt.title('Loss Graph')\n","plt.legend()\n","plt.show()\n","\n","print(\"-----------------------------------------------------------------------------------------\")\n","# plot results for age\n","loss = history4.history['output_age_loss']\n","val_loss = history4.history['val_output_age_loss']\n","epochs = range(len(loss))\n","\n","plt.plot(epochs, loss, 'b', label='Training Loss')\n","plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n","plt.title('Loss Graph')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#For model MobileNetV2\n","\n","# Assuming your input_shape is (224, 224, 3) for MobileNetV2\n","input_shape_mobilenet = (224, 224, 3)\n","\n","# Load the MobileNetV2 model pre-trained on ImageNet data\n","base_model = MobileNetV2(weights=None, include_top=False, input_shape=input_shape_mobilenet)\n"," \n","\n","# Specify the local path to the MobileNetV2 weights file\n","weights_path_MobileNetV2 = '../input/mobilenet-v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5'\n","\n","# Load weights locally\n","base_model.load_weights(weights_path_MobileNetV2)\n","\n","\n","# Set the convolutional base to be non-trainable (freeze the weights)\n","base_model.trainable = False\n","# summarize the base model architecture\n","base_model.summary()\n","print(\"****************************************************************\")\n","# Input layer\n","input_layer = Input(shape=input_shape_mobilenet)\n"," \n","# Pass through MobileNetV2 base model\n","output = base_model(input_layer)\n","\n","# Add custom convolutional layers with reduced downsampling\n","conv_1 = Conv2D(32, kernel_size=(3, 3), activation=\"relu\")(output)\n","maxp_1 = MaxPooling2D(pool_size=(1, 1))(conv_1)\n","\n","conv_2 = Conv2D(64, kernel_size=(3, 3), activation=\"relu\")(maxp_1)\n","maxp_2 = MaxPooling2D(pool_size=(1, 1))(conv_2)\n","\n","conv_3 = Conv2D(128, kernel_size=(3, 3), activation=\"relu\")(maxp_2)\n","maxp_3 = MaxPooling2D(pool_size=(1, 1))(conv_3)\n","\n","conv_4 = Conv2D(160, kernel_size=(1, 1), activation=\"relu\")(maxp_3)\n","\n","# Flatten and add custom dense layers\n","flatten = Flatten()(conv_4)\n","dense_1 = Dense(256, activation=\"relu\")(flatten)\n","dropout_1 = Dropout(0.3)(dense_1)\n","\n","# Output layer for gender prediction\n","output_gender = Dense(1, activation='sigmoid', name='output_gender')(dropout_1)\n","\n","# Output layer for age prediction (using linear activation for regression)\n","output_age = Dense(1, activation='linear', name='output_age')(dropout_1)\n","\n","# Create the MobileNetV2 model with custom layers\n","mobilenet_model = Model(inputs=input_layer, outputs=[output_gender, output_age])\n","\n","# Print a summary of the model architecture\n","mobilenet_model.summary()\n","\n","# Compile the model\n","mobilenet_model.compile(optimizer=Adam(),\n","                               loss=['binary_crossentropy', 'mean_absolute_error'],\n","                               metrics=['accuracy'])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# plot the mobilenet model  \n","plot_model(mobilenet_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Train the mobilenet model  \n","history5 = mobilenet_model.fit(x=X_train, y=[y_gender_train, y_age_train], batch_size=32, epochs=10, validation_data=(X_val, [y_gender_val, y_age_val]))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["##Plot the Results\n","# plot results for gender\n","acc = history5.history['output_gender_accuracy']\n","val_acc = history5.history['val_output_gender_accuracy']\n","epochs = range(len(acc))\n","\n","plt.plot(epochs, acc, 'b', label='Training Accuracy')\n","plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n","plt.title('Accuracy Graph')\n","plt.legend()\n","plt.figure()\n","\n","print(\"-----------------------------------------------------------------------------------------\")\n","# plot results for gender\n","loss = history5.history['output_gender_loss']\n","val_loss = history5.history['val_output_gender_loss']\n","\n","plt.plot(epochs, loss, 'b', label='Training Loss')\n","plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n","plt.title('Loss Graph')\n","plt.legend()\n","plt.show()\n","\n","print(\"-----------------------------------------------------------------------------------------\")\n","# plot results for age\n","loss = history5.history['output_age_loss']\n","val_loss = history5.history['val_output_age_loss']\n","epochs = range(len(loss))\n","\n","plt.plot(epochs, loss, 'b', label='Training Loss')\n","plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n","plt.title('Loss Graph')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Create model DenseNet201\n","\n","# Assuming your input_shape is (224, 224, 3) for DenseNet201\n","input_shape_densenet = (224, 224, 3)\n","\n","# Load the DenseNet201 model pre-trained on ImageNet data\n","base_model = DenseNet201(weights=None, include_top=False, input_shape=input_shape_densenet)\n","\n","# Specify the local path to the DenseNet201 weights file\n","weights_path_DenseNet201 = '../input/densenet201/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5'\n","\n","# Load weights locally\n","base_model.load_weights(weights_path_DenseNet201)\n","\n","# Set the convolutional base to be non-trainable (freeze the weights)\n","base_model.trainable = False\n","# summarize the base model architecture\n","base_model.summary()\n","print(\"****************************************************************\")\n","# Input layer\n","input_layer = Input(shape=input_shape_densenet)\n"," \n","# Pass through DenseNet201 base model\n","output = base_model(input_layer)\n","\n","# Add custom convolutional layers with reduced downsampling\n","conv_1 = Conv2D(32, kernel_size=(3, 3), activation=\"relu\")(output)\n","maxp_1 = MaxPooling2D(pool_size=(1, 1))(conv_1)\n","\n","conv_2 = Conv2D(64, kernel_size=(3, 3), activation=\"relu\")(maxp_1)\n","maxp_2 = MaxPooling2D(pool_size=(1, 1))(conv_2)\n","\n","conv_3 = Conv2D(128, kernel_size=(3, 3), activation=\"relu\")(maxp_2)\n","maxp_3 = MaxPooling2D(pool_size=(1, 1))(conv_3)\n","\n","conv_4 = Conv2D(160, kernel_size=(1, 1), activation=\"relu\")(maxp_3)\n","\n","# Flatten and add custom dense layers\n","flatten = Flatten()(conv_4)\n","dense_1 = Dense(256, activation=\"relu\")(flatten)\n","dropout_1 = Dropout(0.3)(dense_1)\n","\n","# Output layer for gender prediction\n","output_gender = Dense(1, activation='sigmoid', name='output_gender')(dropout_1)\n","\n","# Output layer for age prediction (using linear activation for regression)\n","output_age = Dense(1, activation='linear', name='output_age')(dropout_1)\n","\n","# Create the DenseNet201 model with custom layers\n","densenet_model = Model(inputs=input_layer, outputs=[output_gender, output_age])\n","\n","# Print a summary of the model architecture\n","densenet_model.summary()\n","\n","# Compile the model\n","densenet_model.compile(optimizer=Adam(),\n","                               loss=['binary_crossentropy', 'mean_absolute_error'],\n","                               metrics=['accuracy'])\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# plot the densenet_model model  \n","plot_model(densenet_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Train the Xception model  \n","history6 = xception_model.fit(x=X_train, y=[y_gender_train, y_age_train], batch_size=32, epochs=10, validation_data=(X_val, [y_gender_val, y_age_val]))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["##Plot the Results\n","# plot results for gender\n","acc = history6.history['output_gender_accuracy']\n","val_acc = history6.history['val_output_gender_accuracy']\n","epochs = range(len(acc))\n","\n","plt.plot(epochs, acc, 'b', label='Training Accuracy')\n","plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n","plt.title('Accuracy Graph')\n","plt.legend()\n","plt.figure()\n","\n","print(\"-----------------------------------------------------------------------------------------\")\n","# plot results for gender\n","loss = history6.history['output_gender_loss']\n","val_loss = history6.history['val_output_gender_loss']\n","\n","plt.plot(epochs, loss, 'b', label='Training Loss')\n","plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n","plt.title('Loss Graph')\n","plt.legend()\n","plt.show()\n","\n","print(\"-----------------------------------------------------------------------------------------\")\n","# plot results for age\n","loss = history6.history['output_age_loss']\n","val_loss = history6.history['val_output_age_loss']\n","epochs = range(len(loss))\n","\n","plt.plot(epochs, loss, 'b', label='Training Loss')\n","plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n","plt.title('Loss Graph')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Create model NASNetLarge\n","\n","# Assuming your input_shape is (331, 331, 3) for NASNetLarge\n","input_shape_nasnet = (331, 331, 3)\n","\n","# Load the NASNetLarge model pre-trained on ImageNet data\n","base_model = NASNetLarge(weights=None, include_top=False, input_shape=input_shape_nasnet)\n","\n","# Specify the local path to the NASNetLarge weights file\n","weights_path_NASNetLarge = '../input/nasnet-large/NASNet-large-no-top.h5'\n","\n","# Load weights locally\n","base_model.load_weights(weights_path_NASNetLarge)\n","\n","# Set the convolutional base to be non-trainable (freeze the weights)\n","base_model.trainable = False\n","# summarize the base model architecture\n","base_model.summary()\n","print(\"****************************************************************\")\n","# Input layer\n","input_layer = Input(shape=input_shape_nasnet)\n"," \n","\n","# Pass through NASNetLarge base model\n","output = base_model(input_layer)\n","\n","# Add custom convolutional layers with reduced downsampling\n","conv_1 = Conv2D(32, kernel_size=(3, 3), activation=\"relu\")(output)\n","maxp_1 = MaxPooling2D(pool_size=(1, 1))(conv_1)\n","\n","conv_2 = Conv2D(64, kernel_size=(3, 3), activation=\"relu\")(maxp_1)\n","maxp_2 = MaxPooling2D(pool_size=(1, 1))(conv_2)\n","\n","conv_3 = Conv2D(128, kernel_size=(3, 3), activation=\"relu\")(maxp_2)\n","maxp_3 = MaxPooling2D(pool_size=(1, 1))(conv_3)\n","\n","conv_4 = Conv2D(160, kernel_size=(1, 1), activation=\"relu\")(maxp_3)\n","\n","# Flatten and add custom dense layers\n","flatten = Flatten()(conv_4)\n","dense_1 = Dense(256, activation=\"relu\")(flatten)\n","dropout_1 = Dropout(0.3)(dense_1)\n","\n","# Output layer for gender prediction\n","output_gender = Dense(1, activation='sigmoid', name='output_gender')(dropout_1)\n","\n","# Output layer for age prediction (using linear activation for regression)\n","output_age = Dense(1, activation='linear', name='output_age')(dropout_1)\n","\n","# Create the NASNetLarge model with custom layers\n","nasnet_model = Model(inputs=input_layer, outputs=[output_gender, output_age])\n","\n","# Print a summary of the model architecture\n","nasnet_model.summary()\n","\n","# Compile the model\n","nasnet_model.compile(optimizer=Adam(),\n","                            loss=['binary_crossentropy', 'mean_absolute_error'],\n","                            metrics=['accuracy'])\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# plot the nasnet model  \n","plot_model(nasnet_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Train the Xception model  \n","history7 = nasnet_model.fit(x=X_train, y=[y_gender_train, y_age_train], batch_size=32, epochs=10, validation_data=(X_val, [y_gender_val, y_age_val]))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["##Plot the Results\n","# plot results for gender\n","acc = history7.history['output_gender_accuracy']\n","val_acc = history7.history['val_output_gender_accuracy']\n","epochs = range(len(acc))\n","\n","plt.plot(epochs, acc, 'b', label='Training Accuracy')\n","plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n","plt.title('Accuracy Graph')\n","plt.legend()\n","plt.figure()\n","\n","print(\"-----------------------------------------------------------------------------------------\")\n","# plot results for gender\n","loss = history7.history['output_gender_loss']\n","val_loss = history7.history['val_output_gender_loss']\n","\n","plt.plot(epochs, loss, 'b', label='Training Loss')\n","plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n","plt.title('Loss Graph')\n","plt.legend()\n","plt.show()\n","\n","print(\"-----------------------------------------------------------------------------------------\")\n","# plot results for age\n","loss = history7.history['output_age_loss']\n","val_loss = history7.history['val_output_age_loss']\n","epochs = range(len(loss))\n","\n","plt.plot(epochs, loss, 'b', label='Training Loss')\n","plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n","plt.title('Loss Graph')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#For model EfficientNetB7\n","\n","# Assuming your input_shape is (600, 600, 3) for EfficientNetB7\n","input_shape_efficientnet = (600, 600, 3)\n","\n","# Load the EfficientNetB7 model pre-trained on ImageNet data\n","base_model = EfficientNetB7(weights=None, include_top=False, input_shape=input_shape_efficientnet)\n","\n","# Specify the local path to the EfficientNetB7 weights file\n","weights_path_EfficientNetB7 = '../input/efficientnetb7/efficientnetb7_notop.h5'\n","\n","# Load weights locally\n","base_model.load_weights(weights_path_EfficientNetB7)\n","\n","\n","# Set the convolutional base to be non-trainable (freeze the weights)\n","base_model.trainable = False\n","# summarize the base model architecture\n","base_model.summary()\n","print(\"****************************************************************\")\n","# Input layer\n","input_layer = Input(shape=input_shape_efficientnet)\n"," \n","\n","# Pass through EfficientNetB7 base model\n","output = base_model(input_layer)\n","\n","# Add custom convolutional layers with reduced downsampling\n","conv_1 = Conv2D(32, kernel_size=(3, 3), activation=\"relu\")(output)\n","maxp_1 = MaxPooling2D(pool_size=(1, 1))(conv_1)\n","\n","conv_2 = Conv2D(64, kernel_size=(3, 3), activation=\"relu\")(maxp_1)\n","maxp_2 = MaxPooling2D(pool_size=(1, 1))(conv_2)\n","\n","conv_3 = Conv2D(128, kernel_size=(3, 3), activation=\"relu\")(maxp_2)\n","maxp_3 = MaxPooling2D(pool_size=(1, 1))(conv_3)\n","\n","conv_4 = Conv2D(160, kernel_size=(1, 1), activation=\"relu\")(maxp_3)\n","\n","# Flatten and add custom dense layers\n","flatten = Flatten()(conv_4)\n","dense_1 = Dense(256, activation=\"relu\")(flatten)\n","dropout_1 = Dropout(0.3)(dense_1)\n","\n","# Output layer for gender prediction\n","output_gender = Dense(1, activation='sigmoid', name='output_gender')(dropout_1)\n","\n","# Output layer for age prediction (using linear activation for regression)\n","output_age = Dense(1, activation='linear', name='output_age')(dropout_1)\n","\n","# Create the EfficientNetB7 model with custom layers\n","efficientnet_model = Model(inputs=input_layer, outputs=[output_gender, output_age])\n","\n","# Print a summary of the model architecture\n","efficientnet_model.summary()\n","\n","# Compile the model\n","efficientnet_model.compile(optimizer=Adam(),\n","                                  loss=['binary_crossentropy', 'mean_absolute_error'],\n","                                  metrics=['accuracy'])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# plot the efficientnet model  \n","plot_model(efficientnet_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Train the Xception model  \n","history8 = efficientnet_model.fit(x=X_train, y=[y_gender_train, y_age_train], batch_size=32, epochs=10, validation_data=(X_val, [y_gender_val, y_age_val]))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["##Plot the Results\n","# plot results for gender\n","acc = history8.history['output_gender_accuracy']\n","val_acc = history8.history['val_output_gender_accuracy']\n","epochs = range(len(acc))\n","\n","plt.plot(epochs, acc, 'b', label='Training Accuracy')\n","plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n","plt.title('Accuracy Graph')\n","plt.legend()\n","plt.figure()\n","\n","print(\"-----------------------------------------------------------------------------------------\")\n","# plot results for gender\n","loss = history8.history['output_gender_loss']\n","val_loss = history8.history['val_output_gender_loss']\n","\n","plt.plot(epochs, loss, 'b', label='Training Loss')\n","plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n","plt.title('Loss Graph')\n","plt.legend()\n","plt.show()\n","\n","print(\"-----------------------------------------------------------------------------------------\")\n","# plot results for age\n","loss = history8.history['output_age_loss']\n","val_loss = history8.history['val_output_age_loss']\n","epochs = range(len(loss))\n","\n","plt.plot(epochs, loss, 'b', label='Training Loss')\n","plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n","plt.title('Loss Graph')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Create the model EfficientNetV2L\n","\n","# Assuming your input_shape is (600, 600, 3) for EfficientNetV2L\n","input_shape_efficientnet = (600, 600, 3)\n","\n","# Load the EfficientNetV2L model pre-trained on ImageNet data\n","base_model = EfficientNetV2L(weights=None, include_top=False, input_shape=input_shape_efficientnet)\n","\n","# Specify the local path to the EfficientNetB7 weights file\n","weights_path_EfficientNetV2L = '../input/efficientnetv2-l/efficientnetv2-l_notop.h5'\n","\n","# Load weights locally\n","base_model.load_weights(weights_path_EfficientNetV2L)\n","\n","# Set the convolutional base to be non-trainable (freeze the weights)\n","base_model.trainable = False\n","# summarize the base model architecture\n","base_model.summary()\n","print(\"****************************************************************\")\n","# Input layer\n","input_layer = Input(shape=input_shape_efficientnet)\n"," \n","# Pass through EfficientNetV2L base model\n","output = base_model(input_layer)\n","\n","# Add custom convolutional layers with reduced downsampling\n","conv_1 = Conv2D(32, kernel_size=(3, 3), activation=\"relu\")(output)\n","maxp_1 = MaxPooling2D(pool_size=(1, 1))(conv_1)\n","\n","conv_2 = Conv2D(64, kernel_size=(3, 3), activation=\"relu\")(maxp_1)\n","maxp_2 = MaxPooling2D(pool_size=(1, 1))(conv_2)\n","\n","conv_3 = Conv2D(128, kernel_size=(3, 3), activation=\"relu\")(maxp_2)\n","maxp_3 = MaxPooling2D(pool_size=(1, 1))(conv_3)\n","\n","conv_4 = Conv2D(160, kernel_size=(1, 1), activation=\"relu\")(maxp_3)\n","\n","# Flatten and add custom dense layers\n","flatten = Flatten()(conv_4)\n","dense_1 = Dense(256, activation=\"relu\")(flatten)\n","dropout_1 = Dropout(0.3)(dense_1)\n","\n","# Output layer for gender prediction\n","output_gender = Dense(1, activation='sigmoid', name='output_gender')(dropout_1)\n","\n","# Output layer for age prediction (using linear activation for regression)\n","output_age = Dense(1, activation='linear', name='output_age')(dropout_1)\n","\n","# Create the EfficientNetV2L model with custom layers\n","EfficientNetV2L_model = Model(inputs=input_layer, outputs=[output_gender, output_age])\n","\n","# Print a summary of the model architecture\n","EfficientNetV2L_model.summary()\n","\n","# Compile the model\n","EfficientNetV2L_model.compile(optimizer=Adam(),\n","                                  loss=['binary_crossentropy', 'mean_absolute_error'],\n","                                  metrics=['accuracy'])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# plot the EfficientNetV2L model  \n","plot_model(EfficientNetV2L_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Train the EfficientNetV2L model  \n","history9 = EfficientNetV2L_model.fit(x=X_train, y=[y_gender_train, y_age_train], batch_size=32, epochs=10, validation_data=(X_val, [y_gender_val, y_age_val]))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["##Plot the Results\n","# plot results for gender\n","acc = history9.history['output_gender_accuracy']\n","val_acc = history9.history['val_output_gender_accuracy']\n","epochs = range(len(acc))\n","\n","plt.plot(epochs, acc, 'b', label='Training Accuracy')\n","plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n","plt.title('Accuracy Graph')\n","plt.legend()\n","plt.figure()\n","\n","print(\"-----------------------------------------------------------------------------------------\")\n","# plot results for gender\n","loss = history9.history['output_gender_loss']\n","val_loss = history9.history['val_output_gender_loss']\n","\n","plt.plot(epochs, loss, 'b', label='Training Loss')\n","plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n","plt.title('Loss Graph')\n","plt.legend()\n","plt.show()\n","\n","print(\"-----------------------------------------------------------------------------------------\")\n","# plot results for age\n","loss = history9.history['output_age_loss']\n","val_loss = history9.history['val_output_age_loss']\n","epochs = range(len(loss))\n","\n","plt.plot(epochs, loss, 'b', label='Training Loss')\n","plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n","plt.title('Loss Graph')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Create model ConvNeXtXLarge\n","\n","# Define the input shape\n","input_shape_ConvNeXtXLarge = (224, 224, 3)  # Adjust the input shape as needed\n","\n","# Load the ConvNeXtXLarge model with pre-trained ImageNet weights\n","base_model = ConvNeXtXLarge(weights=None, input_shape=input_shape, include_top=False)\n","# Specify the local path to the ConvNeXtXLarge weights file\n","weights_path_ConvNeXtXLarge = '../input/convnext-xlarge/convnext_xlarge_notop.h5'\n","# Load weights locally\n","base_model.load_weights(weights_path_ConvNeXtXLarge)\n","\n","# Set the convolutional base to be non-trainable (freeze the weights)\n","base_model.trainable = False\n","# summarize the base model architecture\n","base_model.summary()\n","print(\"****************************************************************\")\n","# Input layer\n","input_layer = Input(shape=input_shape_ConvNeXtXLarge)\n"," \n","# Pass through ConvNeXtXLarge base model\n","output = base_model(input_layer)\n","\n","# Add custom convolutional layers with reduced downsampling\n","conv_1 = Conv2D(32, kernel_size=(3, 3), activation=\"relu\")(output)\n","maxp_1 = MaxPooling2D(pool_size=(1, 1))(conv_1)\n","\n","conv_2 = Conv2D(64, kernel_size=(3, 3), activation=\"relu\")(maxp_1)\n","maxp_2 = MaxPooling2D(pool_size=(1, 1))(conv_2)\n","\n","conv_3 = Conv2D(128, kernel_size=(3, 3), activation=\"relu\")(maxp_2)\n","maxp_3 = MaxPooling2D(pool_size=(1, 1))(conv_3)\n","\n","conv_4 = Conv2D(160, kernel_size=(1, 1), activation=\"relu\")(maxp_3)\n","\n","# Flatten and add custom dense layers\n","flatten = Flatten()(conv_4)\n","dense_1 = Dense(256, activation=\"relu\")(flatten)\n","dropout_1 = Dropout(0.3)(dense_1)\n","\n","# Output layer for classification\n","output_classification = Dense(1000, activation='softmax', name='output_classification')(dropout_1)\n","\n","# Create the ConvNeXtXLarge model with custom layers\n","convnext_model = Model(inputs=input_layer, outputs=output_classification)\n","\n","# Print a summary of the model architecture\n","convnext_model.summary()\n","\n","# Compile the model\n","convnext_model.compile(optimizer=Adam(),\n","                              loss='categorical_crossentropy',\n","                              metrics=['accuracy'])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# plot the convnext model  \n","plot_model(convnext_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Train the convnext model  \n","history10 = convnext_model.fit(x=X_train, y=[y_gender_train, y_age_train], batch_size=32, epochs=32, validation_data=(X_val, [y_gender_val, y_age_val]))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["##Plot the Results\n","# plot results for gender\n","acc = history10.history['output_gender_accuracy']\n","val_acc = history10.history['val_output_gender_accuracy']\n","epochs = range(len(acc))\n","\n","plt.plot(epochs, acc, 'b', label='Training Accuracy')\n","plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n","plt.title('Accuracy Graph')\n","plt.legend()\n","plt.figure()\n","\n","print(\"-----------------------------------------------------------------------------------------\")\n","# plot results for gender\n","loss = history10.history['output_gender_loss']\n","val_loss = history10.history['val_output_gender_loss']\n","\n","plt.plot(epochs, loss, 'b', label='Training Loss')\n","plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n","plt.title('Loss Graph')\n","plt.legend()\n","plt.show()\n","\n","print(\"-----------------------------------------------------------------------------------------\")\n","# plot results for age\n","loss = history10.history['output_age_loss']\n","val_loss = history10.history['val_output_age_loss']\n","epochs = range(len(loss))\n","\n","plt.plot(epochs, loss, 'b', label='Training Loss')\n","plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n","plt.title('Loss Graph')\n","plt.legend()\n","plt.show()"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":44109,"sourceId":78156,"sourceType":"datasetVersion"},{"datasetId":3902462,"sourceId":6782204,"sourceType":"datasetVersion"},{"datasetId":3939754,"sourceId":6854145,"sourceType":"datasetVersion"},{"datasetId":3957570,"sourceId":6889256,"sourceType":"datasetVersion"},{"datasetId":3957743,"sourceId":6889495,"sourceType":"datasetVersion"},{"datasetId":3957773,"sourceId":6889541,"sourceType":"datasetVersion"},{"datasetId":3957820,"sourceId":6889608,"sourceType":"datasetVersion"},{"datasetId":3957868,"sourceId":6889684,"sourceType":"datasetVersion"},{"datasetId":3958012,"sourceId":6889945,"sourceType":"datasetVersion"},{"datasetId":3958108,"sourceId":6890098,"sourceType":"datasetVersion"},{"datasetId":3958280,"sourceId":6890413,"sourceType":"datasetVersion"},{"modelInstanceId":2415,"sourceId":3257,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30527,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.0.0"}},"nbformat":4,"nbformat_minor":4}
