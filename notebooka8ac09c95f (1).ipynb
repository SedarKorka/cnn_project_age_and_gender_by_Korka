{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":78156,"sourceType":"datasetVersion","datasetId":44109},{"sourceId":6782204,"sourceType":"datasetVersion","datasetId":3902462},{"sourceId":6854145,"sourceType":"datasetVersion","datasetId":3939754},{"sourceId":6889256,"sourceType":"datasetVersion","datasetId":3957570},{"sourceId":6889495,"sourceType":"datasetVersion","datasetId":3957743},{"sourceId":6889541,"sourceType":"datasetVersion","datasetId":3957773},{"sourceId":6889608,"sourceType":"datasetVersion","datasetId":3957820},{"sourceId":6889684,"sourceType":"datasetVersion","datasetId":3957868},{"sourceId":6889945,"sourceType":"datasetVersion","datasetId":3958012},{"sourceId":6890098,"sourceType":"datasetVersion","datasetId":3958108},{"sourceId":6890413,"sourceType":"datasetVersion","datasetId":3958280},{"sourceId":3257,"sourceType":"modelInstanceVersion","modelInstanceId":2415}],"dockerImageVersionId":30527,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Import model\nimport pandas as pd\nimport numpy as np\nimport os\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\n\nfrom tqdm.notebook import tqdm\n\nfrom PIL import Image\n\n#import warnings\n#warnings.filterwarnings('ignore')\n\n\nfrom tensorflow.keras.utils import plot_model\n\nimport tensorflow as tf\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Dropout, Conv2D, Flatten, MaxPooling2D, Input,BatchNormalization,Activation, GlobalAveragePooling2D, Add\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\n\n#Librairie to split dataset\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.metrics import accuracy_score, mean_absolute_error\n\n#For model Xception\nfrom tensorflow.keras.applications import Xception\n\n#For model VGG19\nfrom tensorflow.keras.applications import VGG19  \n\n# For model ResNet152V2\nfrom tensorflow.keras.applications import ResNet152V2 \n\n#For model InceptionResNetV2 \nfrom tensorflow.keras.applications import InceptionResNetV2\n\n#For model MobileNetV2\nfrom tensorflow.keras.applications import MobileNetV2\n\n#For model DenseNet201\nfrom tensorflow.keras.applications import DenseNet201\n\n#For model NASNetLarge \nfrom tensorflow.keras.applications import NASNetLarge \n\n#For model EfficientNetB7 \nfrom tensorflow.keras.applications import EfficientNetB7 \n\n#For model EfficientNetV2L \nfrom tensorflow.keras.applications import EfficientNetV2L \n\n#For model ConvNeXtXLarge\nfrom tensorflow.keras.applications import ConvNeXtXLarge ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-05T10:42:34.409403Z","iopub.execute_input":"2023-12-05T10:42:34.410418Z","iopub.status.idle":"2023-12-05T10:42:34.428780Z","shell.execute_reply.started":"2023-12-05T10:42:34.410372Z","shell.execute_reply":"2023-12-05T10:42:34.427686Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#Load the dataset\nBASE_DIR = '../input/utkface-new/UTKFace/'","metadata":{"execution":{"iopub.status.busy":"2023-11-29T08:27:01.172120Z","iopub.execute_input":"2023-11-29T08:27:01.173186Z","iopub.status.idle":"2023-11-29T08:27:01.178761Z","shell.execute_reply.started":"2023-11-29T08:27:01.173137Z","shell.execute_reply":"2023-11-29T08:27:01.177865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#label Age, gender and Ethnicity\nimages_paths = []\nage_labels = []\ngender_labels = []\n\nfor filename in tqdm(os.listdir(BASE_DIR)):\n    image_path = os.path.join(BASE_DIR, filename)\n    temps = filename.split(\"_\")\n    ages = int(temps[0])\n    genders = int(temps[1])\n    \n    images_paths.append(image_path)\n    age_labels.append(ages)\n    gender_labels.append(genders)\n    \n    #print(images_paths)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T08:27:05.779825Z","iopub.execute_input":"2023-11-29T08:27:05.780255Z","iopub.status.idle":"2023-11-29T08:27:06.291536Z","shell.execute_reply.started":"2023-11-29T08:27:05.780223Z","shell.execute_reply":"2023-11-29T08:27:06.290428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#transform the dataset to dataFrame\ndata = pd.DataFrame()\n\ndata['image'], data['age'], data['gender'] = images_paths, age_labels, gender_labels\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-04T14:23:38.158259Z","iopub.execute_input":"2023-12-04T14:23:38.158796Z","iopub.status.idle":"2023-12-04T14:23:38.218447Z","shell.execute_reply.started":"2023-12-04T14:23:38.158751Z","shell.execute_reply":"2023-12-04T14:23:38.217271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.size","metadata":{"execution":{"iopub.status.busy":"2023-12-04T14:23:45.029771Z","iopub.execute_input":"2023-12-04T14:23:45.030491Z","iopub.status.idle":"2023-12-04T14:23:45.038393Z","shell.execute_reply.started":"2023-12-04T14:23:45.030442Z","shell.execute_reply":"2023-12-04T14:23:45.037069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#map label for gender\ngender_dic = {0: 'Male', 1:'Femel'}","metadata":{"execution":{"iopub.status.busy":"2023-12-04T14:23:47.924682Z","iopub.execute_input":"2023-12-04T14:23:47.925087Z","iopub.status.idle":"2023-12-04T14:23:47.929071Z","shell.execute_reply.started":"2023-12-04T14:23:47.925058Z","shell.execute_reply":"2023-12-04T14:23:47.928151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom PIL import Image   \n\n \nimage_path = data['image'][130]\n\n# Display the image\nimg = Image.open(image_path)\nplt.imshow(img)\n\n# Extract image name and extension\nimage_name = image_path.split('/')[-1].split('.')[0]  # Adjust the path delimiter if needed\nimage_extension = image_path.split('.')[-1]\n\n# Add text to display image name and extension\ntext = f\"{image_name}.{image_extension}\"\nplt.text(0.5, -0.1, text, ha='center', va='center', transform=plt.gca().transAxes, fontsize=12, color='black')\n\n# Show the plot\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-04T14:24:00.189539Z","iopub.execute_input":"2023-12-04T14:24:00.189924Z","iopub.status.idle":"2023-12-04T14:24:00.512798Z","shell.execute_reply.started":"2023-12-04T14:24:00.189895Z","shell.execute_reply":"2023-12-04T14:24:00.511430Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Diplay the distribution of age and also of the gender \n\n# Plot the distribution of age using a histogram\nplt.figure(figsize=(10, 5))\n \nsns.histplot(data=data, x='age', bins=20, kde=True)\nplt.title('Distribution of Age')\n \n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-04T14:24:13.173495Z","iopub.execute_input":"2023-12-04T14:24:13.173928Z","iopub.status.idle":"2023-12-04T14:24:13.662188Z","shell.execute_reply.started":"2023-12-04T14:24:13.173892Z","shell.execute_reply":"2023-12-04T14:24:13.661261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#scalar the age distribution\n\n# Create an instance of MinMaxScaler\n#scaler = MinMaxScaler()\n# Reshape the 'age' column to a 2D array\n#new_ages = data['age'].values.reshape(-1, 1)\n# Fit the scaler to the 'age' column and compute the minimum and maximum values\n#scaler.fit(new_ages)\n# Transform the 'age' data using the computed minimum and maximum values\n#scaled_age = scaler.transform(new_ages)\n\n# Replace the original 'age' column with the scaled values\n#data['age'] = scaled_age\n\n# Print the first few rows of the modified dataset\n#print(data.head())","metadata":{"execution":{"iopub.status.busy":"2023-11-28T15:58:58.756822Z","iopub.execute_input":"2023-11-28T15:58:58.757128Z","iopub.status.idle":"2023-11-28T15:58:58.762320Z","shell.execute_reply.started":"2023-11-28T15:58:58.757101Z","shell.execute_reply":"2023-11-28T15:58:58.761317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the distribution of age after scaler\n#plt.figure(figsize=(10, 5))\n \n#sns.histplot(data=data, x='age', bins=20, kde=True)\n#plt.title('Distribution of Age After scaled age')\n \n\n#plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-28T15:58:58.766353Z","iopub.execute_input":"2023-11-28T15:58:58.766641Z","iopub.status.idle":"2023-11-28T15:58:58.773834Z","shell.execute_reply.started":"2023-11-28T15:58:58.766617Z","shell.execute_reply":"2023-11-28T15:58:58.772803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the distribution of gender using a count plot\n \n\nplt.figure(figsize=(10, 5))\nax = sns.countplot(data=data, x='gender', color='gray')\nplt.title('Distribution of Gender')\n\n# Add count numbers on top of the bars\nfor p in ax.patches:\n    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2, p.get_height()), ha='center', va='bottom')\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-04T14:24:22.160559Z","iopub.execute_input":"2023-12-04T14:24:22.160960Z","iopub.status.idle":"2023-12-04T14:24:22.374299Z","shell.execute_reply.started":"2023-12-04T14:24:22.160928Z","shell.execute_reply":"2023-12-04T14:24:22.373402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming gender_dict is a dictionary that maps gender codes (0 and 1) to gender labels ('Female' and 'Male')\n\n# to display grid of images\nplt.figure(figsize=(20, 20))\nfiles = data.iloc[0:25]\n\n# Filter data to get only the younger individuals\n#files_younger = data[data['age'] < 30].iloc[0:25]\n\nfor index, file, age, gender in files.itertuples():\n    plt.subplot(5, 5, index+1)\n    img =  Image.open(file)\n    img = np.array(img)\n    plt.imshow(img)\n    plt.title(f\"Age: {age} Gender: {gender_dic[gender]}\")\n    plt.axis('off')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-04T14:24:33.957729Z","iopub.execute_input":"2023-12-04T14:24:33.958127Z","iopub.status.idle":"2023-12-04T14:24:38.051972Z","shell.execute_reply.started":"2023-12-04T14:24:33.958097Z","shell.execute_reply":"2023-12-04T14:24:38.048740Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_features(images):\n    features = []\n    for image in tqdm(images):\n        img = Image.open(image).convert('L')  # Convert to grayscale\n        img = img.resize((128, 128), Image.LANCZOS)  # Use LANCZOS for resizing\n        features.append(np.array(img))  # Convert the image to a NumPy array\n\n    # Check the shapes of the images in the features list\n    shapes = set(img.shape for img in features)\n    if len(shapes) > 1:\n        raise ValueError(\"Images have different sizes or shapes.\")\n\n    features = np.array(features)\n    # Reshape the features array to add the channel dimension (1 for grayscale)\n    features = features.reshape(len(features), 128, 128, 1)\n    return features","metadata":{"execution":{"iopub.status.busy":"2023-12-04T14:25:46.250889Z","iopub.execute_input":"2023-12-04T14:25:46.251303Z","iopub.status.idle":"2023-12-04T14:25:46.259473Z","shell.execute_reply.started":"2023-12-04T14:25:46.251271Z","shell.execute_reply":"2023-12-04T14:25:46.258271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming 'data' is your DataFrame containing image paths in the 'image' column\nExtractions = extract_features(data['image'])","metadata":{"execution":{"iopub.status.busy":"2023-12-04T14:25:51.132516Z","iopub.execute_input":"2023-12-04T14:25:51.132942Z","iopub.status.idle":"2023-12-04T14:26:34.599081Z","shell.execute_reply.started":"2023-12-04T14:25:51.132911Z","shell.execute_reply":"2023-12-04T14:26:34.597865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Extractions.shape","metadata":{"execution":{"iopub.status.busy":"2023-12-04T14:26:46.631728Z","iopub.execute_input":"2023-12-04T14:26:46.632132Z","iopub.status.idle":"2023-12-04T14:26:46.639408Z","shell.execute_reply.started":"2023-12-04T14:26:46.632101Z","shell.execute_reply":"2023-12-04T14:26:46.638288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Normalize the extraction\nExtractions = Extractions /255.0","metadata":{"execution":{"iopub.status.busy":"2023-12-04T14:26:50.272449Z","iopub.execute_input":"2023-12-04T14:26:50.272844Z","iopub.status.idle":"2023-12-04T14:26:51.642616Z","shell.execute_reply.started":"2023-12-04T14:26:50.272814Z","shell.execute_reply":"2023-12-04T14:26:51.641559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_gender = np.array(data['gender'])\ny_age = np.array(data['age'])","metadata":{"execution":{"iopub.status.busy":"2023-12-04T14:26:53.913179Z","iopub.execute_input":"2023-12-04T14:26:53.913592Z","iopub.status.idle":"2023-12-04T14:26:53.919956Z","shell.execute_reply.started":"2023-12-04T14:26:53.913551Z","shell.execute_reply":"2023-12-04T14:26:53.917926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_shape = (128, 128, 1)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T14:27:02.007091Z","iopub.execute_input":"2023-12-04T14:27:02.007888Z","iopub.status.idle":"2023-12-04T14:27:02.013489Z","shell.execute_reply.started":"2023-12-04T14:27:02.007852Z","shell.execute_reply":"2023-12-04T14:27:02.011845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Split the dataset into training and validation sets\nX_train, X_val, y_gender_train, y_gender_val, y_age_train, y_age_val = train_test_split(\n    Extractions, y_gender, y_age, test_size=0.2, random_state=42)\n\n# Now, you have:\n# - X_train: Training data\n# - X_val: Validation data\n# - y_gender_train: Training labels for gender\n# - y_gender_val: Validation labels for gender\n# - y_age_train: Training labels for age\n# - y_age_val: Validation labels for age","metadata":{"execution":{"iopub.status.busy":"2023-12-04T14:27:04.950017Z","iopub.execute_input":"2023-12-04T14:27:04.950455Z","iopub.status.idle":"2023-12-04T14:27:06.151982Z","shell.execute_reply.started":"2023-12-04T14:27:04.950420Z","shell.execute_reply":"2023-12-04T14:27:06.150724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create Xception model\n\ninput_shape_xception = input_shape\n\n# Load the Xception model pre-trained on ImageNet data\nbase_model = Xception(weights=None, include_top=False, input_shape=input_shape_xception)\n\n# Specify the local path to the Xception weights file\nweights_path_Xception = '../input/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\n# Load weights locally\n#base_model.load_weights(weights_path_Xception)\nbase_model.load_weights(weights_path_Xception, by_name=True)\n\n\n# Set the convolutional base to be non-trainable (freeze the weights)\nbase_model.trainable = False\n# summarize the base model architecture\nbase_model.summary()\nprint(\"****************************************************************\")\n# Input layer\ninput_layer = Input(shape=input_shape_xception)\n\n\n# Pass through Xception base model\ninputs = base_model(input_layer)\n\n# Add custom convolutional layers with reduced downsampling\nconv_1 = Conv2D(32, kernel_size=(3, 3), activation='relu')(inputs)\nmaxp_1 = MaxPooling2D(pool_size=(1, 1))(conv_1)\nconv_2 = Conv2D(64, kernel_size=(1, 1), activation='relu')(maxp_1)\nmaxp_2 = MaxPooling2D(pool_size=(1, 1))(conv_2)\nconv_3 = Conv2D(128, kernel_size=(1, 1), activation='relu')(maxp_2)\nmaxp_3 = MaxPooling2D(pool_size=(1, 1))(conv_3)\nconv_4 = Conv2D(256, kernel_size=(1, 1), activation='relu')(maxp_3)\nmaxp_4 = MaxPooling2D(pool_size=(1, 1))(conv_4)\n\n# Flatten and add custom dense layers\nflatten = Flatten()(maxp_4)\ndense_1 = Dense(256, activation=\"relu\")(flatten)\ndropout_1 = Dropout(0.3)(dense_1)\n\n# Output layer for gender prediction\noutput_gender = Dense(1, activation='sigmoid', name='output_gender')(dropout_1)\n\n# Output layer for age prediction (using linear activation for regression)\noutput_age = Dense(1, activation='linear', name='output_age')(dropout_1)\n\n# Create the Xception model with custom layers\nxception_model = Model(inputs=input_layer, outputs=[output_gender, output_age])\n\n# Print a summary of the model architecture\nxception_model.summary()\n\n# Compile the model\nxception_model.compile(optimizer=Adam(),\n                               loss=['binary_crossentropy', 'mean_absolute_error'],\n                               metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2023-12-04T14:27:12.941593Z","iopub.execute_input":"2023-12-04T14:27:12.941979Z","iopub.status.idle":"2023-12-04T14:27:16.300301Z","shell.execute_reply.started":"2023-12-04T14:27:12.941949Z","shell.execute_reply":"2023-12-04T14:27:16.299023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot the Xception model  \nplot_model(xception_model)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T14:27:29.107104Z","iopub.execute_input":"2023-12-04T14:27:29.107708Z","iopub.status.idle":"2023-12-04T14:27:29.411730Z","shell.execute_reply.started":"2023-12-04T14:27:29.107652Z","shell.execute_reply":"2023-12-04T14:27:29.410809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the Xception model  \nhistory1 = xception_model.fit(x=X_train, y=[y_gender_train, y_age_train], batch_size=32, epochs=10, validation_data=(X_val, [y_gender_val, y_age_val]))\n","metadata":{"execution":{"iopub.status.busy":"2023-12-04T14:27:38.547904Z","iopub.execute_input":"2023-12-04T14:27:38.548366Z","iopub.status.idle":"2023-12-04T16:40:35.165558Z","shell.execute_reply.started":"2023-12-04T14:27:38.548314Z","shell.execute_reply":"2023-12-04T16:40:35.164152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Plot the Results\n# plot results for gender\nacc = history1.history['output_gender_accuracy']\nval_acc = history1.history['val_output_gender_accuracy']\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'b', label='Training Accuracy')\nplt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\nplt.title('Accuracy Graph')\nplt.legend()\nplt.figure()\n\nprint(\"-----------------------------------------------------------------------------------------\")\n# plot results for gender\nloss = history1.history['output_gender_loss']\nval_loss = history1.history['val_output_gender_loss']\n\nplt.plot(epochs, loss, 'b', label='Training Loss')\nplt.plot(epochs, val_loss, 'r', label='Validation Loss')\nplt.title('Loss Graph')\nplt.legend()\nplt.show()\n\nprint(\"-----------------------------------------------------------------------------------------\")\n# plot results for age\nloss = history1.history['output_age_loss']\nval_loss = history1.history['val_output_age_loss']\nepochs = range(len(loss))\n\nplt.plot(epochs, loss, 'b', label='Training Loss')\nplt.plot(epochs, val_loss, 'r', label='Validation Loss')\nplt.title('Loss Graph')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-04T16:47:05.615483Z","iopub.execute_input":"2023-12-04T16:47:05.615935Z","iopub.status.idle":"2023-12-04T16:47:06.391085Z","shell.execute_reply.started":"2023-12-04T16:47:05.615903Z","shell.execute_reply":"2023-12-04T16:47:06.389823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#The prediction with xception model \n##Test 1\n#Prediction with Test Data\nimage_index = 100\nprint(\"Original Gender:\", gender_dic[y_gender[image_index]], \"Original Age:\", y_age[image_index])\n# predict from model\npred = xception_model.predict(Extractions[image_index].reshape(1, 128, 128, 1))\npred_gender = gender_dic[round(pred[0][0][0])]\npred_age = round(pred[1][0][0])\nprint(\"Predicted Gender:\", pred_gender, \"Predicted Age:\", pred_age)\nplt.axis('off')\nplt.imshow(Extractions[image_index].reshape(128, 128), cmap='gray');","metadata":{"execution":{"iopub.status.busy":"2023-12-04T16:47:16.837026Z","iopub.execute_input":"2023-12-04T16:47:16.837453Z","iopub.status.idle":"2023-12-04T16:47:18.070910Z","shell.execute_reply.started":"2023-12-04T16:47:16.837420Z","shell.execute_reply":"2023-12-04T16:47:18.069343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Test 2\n#Prediction with Test Data\nimage_index = 980\nprint(\"Original Gender:\", gender_dic[y_gender[image_index]], \"Original Age:\", y_age[image_index])\n# predict from model\npred = xception_model.predict(Extractions[image_index].reshape(1, 128, 128, 1))\npred_gender = gender_dic[round(pred[0][0][0])]\npred_age = round(pred[1][0][0])\nprint(\"Predicted Gender:\", pred_gender, \"Predicted Age:\", pred_age)\nplt.axis('off')\nplt.imshow(Extractions[image_index].reshape(128, 128), cmap='gray');\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-04T16:47:23.986761Z","iopub.execute_input":"2023-12-04T16:47:23.987177Z","iopub.status.idle":"2023-12-04T16:47:24.291443Z","shell.execute_reply.started":"2023-12-04T16:47:23.987143Z","shell.execute_reply":"2023-12-04T16:47:24.289545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Test 3\n#Prediction with Test Data\nimage_index = 666\nprint(\"Original Gender:\", gender_dic[y_gender[image_index]], \"Original Age:\", y_age[image_index])\n# predict from model\npred = xception_model.predict(Extractions[image_index].reshape(1, 128, 128, 1))\npred_gender = gender_dic[round(pred[0][0][0])]\npred_age = round(pred[1][0][0])\nprint(\"Predicted Gender:\", pred_gender, \"Predicted Age:\", pred_age)\nplt.axis('off')\nplt.imshow(Extractions[image_index].reshape(128, 128), cmap='gray');","metadata":{"execution":{"iopub.status.busy":"2023-12-04T16:47:32.138501Z","iopub.execute_input":"2023-12-04T16:47:32.138974Z","iopub.status.idle":"2023-12-04T16:47:32.459278Z","shell.execute_reply.started":"2023-12-04T16:47:32.138941Z","shell.execute_reply":"2023-12-04T16:47:32.457702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create a VGG16 model\n \ninput_shape_vgg19 = input_shape\n\n# Load the VGG19 model pre-trained on ImageNet data\nbase_model = VGG19(weights=None, include_top=False, input_shape=input_shape_vgg19)\n\n# Specify the local path to the VGG19 weights file\nweights_path_VGG19 = '../input/vgg19-weights-tf-dim-ordering-tf-kernels-notop-h5/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\n# Load weights locally\nbase_model.load_weights(weights_path_VGG19, by_name=True, skip_mismatch=True)\n# Set the convolutional base to be non-trainable (freeze the weights)\nbase_model.trainable = False\n# Let's take a look at the base model architecture\nbase_model.summary()\nprint(\"****************************************************************\")\n\n\n\n# Input layer\ninput_layer = Input(shape=input_shape_vgg19)\n \n\n# Pass through VGG19 base model\ninputs = base_model(input_layer)\n\n# Add custom convolutional layers with reduced downsampling\nconv_1 = Conv2D(32, kernel_size=(3, 3), activation='relu')(inputs)\nmaxp_1 = MaxPooling2D(pool_size=(1, 1))(conv_1)\nconv_2 = Conv2D(64, kernel_size=(1, 1), activation='relu')(maxp_1)\nmaxp_2 = MaxPooling2D(pool_size=(1, 1))(conv_2)\nconv_3 = Conv2D(128, kernel_size=(1, 1), activation='relu')(maxp_2)\nmaxp_3 = MaxPooling2D(pool_size=(1, 1))(conv_3)\nconv_4 = Conv2D(256, kernel_size=(1, 1), activation='relu')(maxp_3)\nmaxp_4 = MaxPooling2D(pool_size=(1, 1))(conv_4)\n\n# Flatten and add custom dense layers\nflatten = Flatten()(maxp_4)\ndense_1 = Dense(256, activation=\"relu\")(flatten)\ndropout_1 = Dropout(0.3)(dense_1)\n\n# Output layer for gender prediction\noutput_gender = Dense(1, activation='sigmoid', name='output_gender')(dropout_1)\n\n# Output layer for age prediction (using linear activation for regression)\noutput_age = Dense(1, activation='linear', name='output_age')(dropout_1)\n\n# Create the VGG19 model with custom layers\nvgg19_model = Model(inputs=input_layer, outputs=[output_gender, output_age])\n\n# Print a summary of the model architecture\nvgg19_model.summary()\n\n# Compile the model\nvgg19_model.compile(optimizer=Adam(),\n                            loss=['binary_crossentropy', 'mean_absolute_error'],\n                            metrics=['accuracy'])\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-04T16:47:43.350409Z","iopub.execute_input":"2023-12-04T16:47:43.351553Z","iopub.status.idle":"2023-12-04T16:47:45.305186Z","shell.execute_reply.started":"2023-12-04T16:47:43.351517Z","shell.execute_reply":"2023-12-04T16:47:45.303930Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot the vgg19_model model  \nplot_model(vgg19_model)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T16:47:52.358742Z","iopub.execute_input":"2023-12-04T16:47:52.359182Z","iopub.status.idle":"2023-12-04T16:47:52.483768Z","shell.execute_reply.started":"2023-12-04T16:47:52.359148Z","shell.execute_reply":"2023-12-04T16:47:52.482650Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the Xception model  \nhistory2 = vgg19_model.fit(x=X_train, y=[y_gender_train, y_age_train], batch_size=32, epochs=10, validation_data=(X_val, [y_gender_val, y_age_val]))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Plot the Results\n# plot results for gender\nacc = history2.history['output_gender_accuracy']\nval_acc = history2.history['val_output_gender_accuracy']\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'b', label='Training Accuracy')\nplt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\nplt.title('Accuracy Graph')\nplt.legend()\nplt.figure()\n\nprint(\"-----------------------------------------------------------------------------------------\")\n# plot results for gender\nloss = history2.history['output_gender_loss']\nval_loss = history2.history['val_output_gender_loss']\n\nplt.plot(epochs, loss, 'b', label='Training Loss')\nplt.plot(epochs, val_loss, 'r', label='Validation Loss')\nplt.title('Loss Graph')\nplt.legend()\nplt.show()\n\nprint(\"-----------------------------------------------------------------------------------------\")\n# plot results for age\nloss = history2.history['output_age_loss']\nval_loss = history2.history['val_output_age_loss']\nepochs = range(len(loss))\n\nplt.plot(epochs, loss, 'b', label='Training Loss')\nplt.plot(epochs, val_loss, 'r', label='Validation Loss')\nplt.title('Loss Graph')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#The prediction with xception model \n##Test 1\n#Prediction with Test Data\nimage_index = 100\nprint(\"Original Gender:\", gender_dic[y_gender[image_index]], \"Original Age:\", y_age[image_index])\n# predict from model\npred = vgg19_model.predict(Extractions[image_index].reshape(1, 128, 128, 1))\npred_gender = gender_dic[round(pred[0][0][0])]\npred_age = round(pred[1][0][0])\nprint(\"Predicted Gender:\", pred_gender, \"Predicted Age:\", pred_age)\nplt.axis('off')\nplt.imshow(Extractions[image_index].reshape(128, 128), cmap='gray');\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#The prediction with xception model \n##Test 1\n#Prediction with Test Data\nimage_index = 980\nprint(\"Original Gender:\", gender_dic[y_gender[image_index]], \"Original Age:\", y_age[image_index])\n# predict from model\npred = vgg19_model.predict(Extractions[image_index].reshape(1, 128, 128, 1))\npred_gender = gender_dic[round(pred[0][0][0])]\npred_age = round(pred[1][0][0])\nprint(\"Predicted Gender:\", pred_gender, \"Predicted Age:\", pred_age)\nplt.axis('off')\nplt.imshow(Extractions[image_index].reshape(128, 128), cmap='gray');\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#The prediction with xception model \n##Test 3\n#Prediction with Test Data\nimage_index = 666\nprint(\"Original Gender:\", gender_dic[y_gender[image_index]], \"Original Age:\", y_age[image_index])\n# predict from model\npred = vgg19_model.predict(Extractions[image_index].reshape(1, 128, 128, 1))\npred_gender = gender_dic[round(pred[0][0][0])]\npred_age = round(pred[1][0][0])\nprint(\"Predicted Gender:\", pred_gender, \"Predicted Age:\", pred_age)\nplt.axis('off')\nplt.imshow(Extractions[image_index].reshape(128, 128), cmap='gray');\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create a ResNet152V2\n\n# Assuming your input_shape is (224, 224, 3) for ResNet152V2\ninput_shape_resnet152v2 = (224, 224, 3)\n\n# Load the ResNet152V2 model pre-trained on ImageNet data\nbase_model = ResNet152V2(weights=None, include_top=False, input_shape=input_shape_resnet152v2)\n\n# Specify the local path to the ResNet152V2 weights file\nweights_path_restNet = '../input/resnet152v2/resnet152v2_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\n# Load weights locally\nbase_model.load_weights(weights_path_restNet)\n\n# Set the convolutional base to be non-trainable (freeze the weights)\nbase_model.trainable = False\n# summarize the base model architecture\nbase_model.summary()\nprint(\"****************************************************************\")\n# Input layer\ninput_layer = Input(shape=input_shape_resnet152v2)\n \n# Pass through ResNet152V2 base model\noutput = base_model(input_layer)\n\n# Add custom convolutional layers with reduced downsampling\nconv_1 = Conv2D(32, kernel_size=(3, 3), activation=\"relu\")(output)\nmaxp_1 = MaxPooling2D(pool_size=(1, 1))(conv_1)\n\nconv_2 = Conv2D(64, kernel_size=(3, 3), activation=\"relu\")(maxp_1)\nmaxp_2 = MaxPooling2D(pool_size=(1, 1))(conv_2)\n\nconv_3 = Conv2D(128, kernel_size=(3, 3), activation=\"relu\")(maxp_2)\nmaxp_3 = MaxPooling2D(pool_size=(1, 1))(conv_3)\n\nconv_4 = Conv2D(160, kernel_size=(1, 1), activation=\"relu\")(maxp_3)\n\n# Flatten and add custom dense layers\nflatten = Flatten()(conv_4)\ndense_1 = Dense(256, activation=\"relu\")(flatten)\ndropout_1 = Dropout(0.3)(dense_1)\n\n# Output layer for gender prediction\noutput_gender = Dense(1, activation='sigmoid', name='output_gender')(dropout_1)\n\n# Output layer for age prediction (using linear activation for regression)\noutput_age = Dense(1, activation='linear', name='output_age')(dropout_1)\n\n# Create the ResNet152V2 model with custom layers\nresnet152v2_model = Model(inputs=input_layer, outputs=[output_gender, output_age])\n\n# Print a summary of the model architecture\nresnet152v2_model.summary()\n\n# Compile the model\nresnet152v2_model.compile(optimizer=Adam(),\n                                  loss=['binary_crossentropy', 'mean_absolute_error'],\n                                  metrics=['accuracy'])\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot the resnet152v2 model  \nplot_model(resnet152v2_model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the Xception model  \nhistory3 = resnet152v2_model.fit(x=X_train, y=[y_gender_train, y_age_train], batch_size=32, epochs=10, validation_data=(X_val, [y_gender_val, y_age_val]))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Plot the Results\n# plot results for gender\nacc = history3.history['output_gender_accuracy']\nval_acc = history3.history['val_output_gender_accuracy']\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'b', label='Training Accuracy')\nplt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\nplt.title('Accuracy Graph')\nplt.legend()\nplt.figure()\n\nprint(\"-----------------------------------------------------------------------------------------\")\n# plot results for gender\nloss = history3.history['output_gender_loss']\nval_loss = history3.history['val_output_gender_loss']\n\nplt.plot(epochs, loss, 'b', label='Training Loss')\nplt.plot(epochs, val_loss, 'r', label='Validation Loss')\nplt.title('Loss Graph')\nplt.legend()\nplt.show()\n\nprint(\"-----------------------------------------------------------------------------------------\")\n# plot results for age\nloss = history3.history['output_age_loss']\nval_loss = history3.history['val_output_age_loss']\nepochs = range(len(loss))\n\nplt.plot(epochs, loss, 'b', label='Training Loss')\nplt.plot(epochs, val_loss, 'r', label='Validation Loss')\nplt.title('Loss Graph')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create  InceptionResNetV2 model\n\n# Assuming your input_shape is (299, 299, 3) for InceptionResNetV2\ninput_shape_inception = (299, 299, 3)\n\n# Load the InceptionResNetV2 model pre-trained on ImageNet data\nbase_model = InceptionResNetV2(weights=None, include_top=False, input_shape=input_shape_inception)\n\n# Specify the local path to the InceptionResNetV2 weights file\nweights_path_InceptionResNetV2 = '../input/inception-resnet-v2-weights/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\n# Load weights locally\nbase_model.load_weights(weights_path_InceptionResNetV2)\n\n# Set the convolutional base to be non-trainable (freeze the weights)\nbase_model.trainable = False\n# summarize the base model architecture\nbase_model.summary()\nprint(\"****************************************************************\")\n# Input layer\ninput_layer = Input(shape=input_shape_inception)\n \n# Pass through InceptionResNetV2 base model\noutput = base_model(input_layer)\n\n# Add custom convolutional layers with reduced downsampling\nconv_1 = Conv2D(32, kernel_size=(3, 3), activation=\"relu\")(output)\nmaxp_1 = MaxPooling2D(pool_size=(1, 1))(conv_1)\n\nconv_2 = Conv2D(64, kernel_size=(1, 1), activation=\"relu\")(maxp_1)  # Reduced the kernel size\nmaxp_2 = MaxPooling2D(pool_size=(1, 1))(conv_2)\n\nconv_3 = Conv2D(128, kernel_size=(1, 1), activation=\"relu\")(maxp_2)  # Reduced the kernel size\n\nmaxp_3 = MaxPooling2D(pool_size=(2, 2))(conv_3)\n\nconv_4 = Conv2D(160, kernel_size=(1, 1), activation=\"relu\")(maxp_3)\n\n# Flatten and add custom dense layers\nflatten = Flatten()(conv_4)\ndense_1 = Dense(256, activation=\"relu\")(flatten)\ndropout_1 = Dropout(0.3)(dense_1)\n\n# Output layer for gender prediction\noutput_gender = Dense(1, activation='sigmoid', name='output_gender')(dropout_1)\n\n# Output layer for age prediction (using linear activation for regression)\noutput_age = Dense(1, activation='linear', name='output_age')(dropout_1)\n\n# Create the InceptionResNetV2 model with custom layers\ninception_model = Model(inputs=input_layer, outputs=[output_gender, output_age])\n\n# Print a summary of the model architecture\ninception_model.summary()\n\n# Compile the model\ninception_model.compile(optimizer=Adam(),\n                               loss=['binary_crossentropy', 'mean_absolute_error'],\n                               metrics=['accuracy'])\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot the inception model  \nplot_model(inception_model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the Xception model  \nhistory4 = plot_model.fit(x=X_train, y=[y_gender_train, y_age_train], batch_size=32, epochs=10, validation_data=(X_val, [y_gender_val, y_age_val]))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Plot the Results\n# plot results for gender\nacc = history4.history['output_gender_accuracy']\nval_acc = history4.history['val_output_gender_accuracy']\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'b', label='Training Accuracy')\nplt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\nplt.title('Accuracy Graph')\nplt.legend()\nplt.figure()\n\nprint(\"-----------------------------------------------------------------------------------------\")\n# plot results for gender\nloss = history4.history['output_gender_loss']\nval_loss = history4.history['val_output_gender_loss']\n\nplt.plot(epochs, loss, 'b', label='Training Loss')\nplt.plot(epochs, val_loss, 'r', label='Validation Loss')\nplt.title('Loss Graph')\nplt.legend()\nplt.show()\n\nprint(\"-----------------------------------------------------------------------------------------\")\n# plot results for age\nloss = history4.history['output_age_loss']\nval_loss = history4.history['val_output_age_loss']\nepochs = range(len(loss))\n\nplt.plot(epochs, loss, 'b', label='Training Loss')\nplt.plot(epochs, val_loss, 'r', label='Validation Loss')\nplt.title('Loss Graph')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#For model MobileNetV2\n\n# Assuming your input_shape is (224, 224, 3) for MobileNetV2\ninput_shape_mobilenet = (224, 224, 3)\n\n# Load the MobileNetV2 model pre-trained on ImageNet data\nbase_model = MobileNetV2(weights=None, include_top=False, input_shape=input_shape_mobilenet)\n \n\n# Specify the local path to the MobileNetV2 weights file\nweights_path_MobileNetV2 = '../input/mobilenet-v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5'\n\n# Load weights locally\nbase_model.load_weights(weights_path_MobileNetV2)\n\n\n# Set the convolutional base to be non-trainable (freeze the weights)\nbase_model.trainable = False\n# summarize the base model architecture\nbase_model.summary()\nprint(\"****************************************************************\")\n# Input layer\ninput_layer = Input(shape=input_shape_mobilenet)\n \n# Pass through MobileNetV2 base model\noutput = base_model(input_layer)\n\n# Add custom convolutional layers with reduced downsampling\nconv_1 = Conv2D(32, kernel_size=(3, 3), activation=\"relu\")(output)\nmaxp_1 = MaxPooling2D(pool_size=(1, 1))(conv_1)\n\nconv_2 = Conv2D(64, kernel_size=(3, 3), activation=\"relu\")(maxp_1)\nmaxp_2 = MaxPooling2D(pool_size=(1, 1))(conv_2)\n\nconv_3 = Conv2D(128, kernel_size=(3, 3), activation=\"relu\")(maxp_2)\nmaxp_3 = MaxPooling2D(pool_size=(1, 1))(conv_3)\n\nconv_4 = Conv2D(160, kernel_size=(1, 1), activation=\"relu\")(maxp_3)\n\n# Flatten and add custom dense layers\nflatten = Flatten()(conv_4)\ndense_1 = Dense(256, activation=\"relu\")(flatten)\ndropout_1 = Dropout(0.3)(dense_1)\n\n# Output layer for gender prediction\noutput_gender = Dense(1, activation='sigmoid', name='output_gender')(dropout_1)\n\n# Output layer for age prediction (using linear activation for regression)\noutput_age = Dense(1, activation='linear', name='output_age')(dropout_1)\n\n# Create the MobileNetV2 model with custom layers\nmobilenet_model = Model(inputs=input_layer, outputs=[output_gender, output_age])\n\n# Print a summary of the model architecture\nmobilenet_model.summary()\n\n# Compile the model\nmobilenet_model.compile(optimizer=Adam(),\n                               loss=['binary_crossentropy', 'mean_absolute_error'],\n                               metrics=['accuracy'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot the mobilenet model  \nplot_model(mobilenet_model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the mobilenet model  \nhistory5 = mobilenet_model.fit(x=X_train, y=[y_gender_train, y_age_train], batch_size=32, epochs=10, validation_data=(X_val, [y_gender_val, y_age_val]))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Plot the Results\n# plot results for gender\nacc = history5.history['output_gender_accuracy']\nval_acc = history5.history['val_output_gender_accuracy']\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'b', label='Training Accuracy')\nplt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\nplt.title('Accuracy Graph')\nplt.legend()\nplt.figure()\n\nprint(\"-----------------------------------------------------------------------------------------\")\n# plot results for gender\nloss = history5.history['output_gender_loss']\nval_loss = history5.history['val_output_gender_loss']\n\nplt.plot(epochs, loss, 'b', label='Training Loss')\nplt.plot(epochs, val_loss, 'r', label='Validation Loss')\nplt.title('Loss Graph')\nplt.legend()\nplt.show()\n\nprint(\"-----------------------------------------------------------------------------------------\")\n# plot results for age\nloss = history5.history['output_age_loss']\nval_loss = history5.history['val_output_age_loss']\nepochs = range(len(loss))\n\nplt.plot(epochs, loss, 'b', label='Training Loss')\nplt.plot(epochs, val_loss, 'r', label='Validation Loss')\nplt.title('Loss Graph')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create model DenseNet201\n\n# Assuming your input_shape is (224, 224, 3) for DenseNet201\ninput_shape_densenet = (224, 224, 3)\n\n# Load the DenseNet201 model pre-trained on ImageNet data\nbase_model = DenseNet201(weights=None, include_top=False, input_shape=input_shape_densenet)\n\n# Specify the local path to the DenseNet201 weights file\nweights_path_DenseNet201 = '../input/densenet201/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\n# Load weights locally\nbase_model.load_weights(weights_path_DenseNet201)\n\n# Set the convolutional base to be non-trainable (freeze the weights)\nbase_model.trainable = False\n# summarize the base model architecture\nbase_model.summary()\nprint(\"****************************************************************\")\n# Input layer\ninput_layer = Input(shape=input_shape_densenet)\n \n# Pass through DenseNet201 base model\noutput = base_model(input_layer)\n\n# Add custom convolutional layers with reduced downsampling\nconv_1 = Conv2D(32, kernel_size=(3, 3), activation=\"relu\")(output)\nmaxp_1 = MaxPooling2D(pool_size=(1, 1))(conv_1)\n\nconv_2 = Conv2D(64, kernel_size=(3, 3), activation=\"relu\")(maxp_1)\nmaxp_2 = MaxPooling2D(pool_size=(1, 1))(conv_2)\n\nconv_3 = Conv2D(128, kernel_size=(3, 3), activation=\"relu\")(maxp_2)\nmaxp_3 = MaxPooling2D(pool_size=(1, 1))(conv_3)\n\nconv_4 = Conv2D(160, kernel_size=(1, 1), activation=\"relu\")(maxp_3)\n\n# Flatten and add custom dense layers\nflatten = Flatten()(conv_4)\ndense_1 = Dense(256, activation=\"relu\")(flatten)\ndropout_1 = Dropout(0.3)(dense_1)\n\n# Output layer for gender prediction\noutput_gender = Dense(1, activation='sigmoid', name='output_gender')(dropout_1)\n\n# Output layer for age prediction (using linear activation for regression)\noutput_age = Dense(1, activation='linear', name='output_age')(dropout_1)\n\n# Create the DenseNet201 model with custom layers\ndensenet_model = Model(inputs=input_layer, outputs=[output_gender, output_age])\n\n# Print a summary of the model architecture\ndensenet_model.summary()\n\n# Compile the model\ndensenet_model.compile(optimizer=Adam(),\n                               loss=['binary_crossentropy', 'mean_absolute_error'],\n                               metrics=['accuracy'])\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot the densenet_model model  \nplot_model(densenet_model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the Xception model  \nhistory6 = xception_model.fit(x=X_train, y=[y_gender_train, y_age_train], batch_size=32, epochs=10, validation_data=(X_val, [y_gender_val, y_age_val]))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Plot the Results\n# plot results for gender\nacc = history6.history['output_gender_accuracy']\nval_acc = history6.history['val_output_gender_accuracy']\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'b', label='Training Accuracy')\nplt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\nplt.title('Accuracy Graph')\nplt.legend()\nplt.figure()\n\nprint(\"-----------------------------------------------------------------------------------------\")\n# plot results for gender\nloss = history6.history['output_gender_loss']\nval_loss = history6.history['val_output_gender_loss']\n\nplt.plot(epochs, loss, 'b', label='Training Loss')\nplt.plot(epochs, val_loss, 'r', label='Validation Loss')\nplt.title('Loss Graph')\nplt.legend()\nplt.show()\n\nprint(\"-----------------------------------------------------------------------------------------\")\n# plot results for age\nloss = history6.history['output_age_loss']\nval_loss = history6.history['val_output_age_loss']\nepochs = range(len(loss))\n\nplt.plot(epochs, loss, 'b', label='Training Loss')\nplt.plot(epochs, val_loss, 'r', label='Validation Loss')\nplt.title('Loss Graph')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create model NASNetLarge\n\n# Assuming your input_shape is (331, 331, 3) for NASNetLarge\ninput_shape_nasnet = (331, 331, 3)\n\n# Load the NASNetLarge model pre-trained on ImageNet data\nbase_model = NASNetLarge(weights=None, include_top=False, input_shape=input_shape_nasnet)\n\n# Specify the local path to the NASNetLarge weights file\nweights_path_NASNetLarge = '../input/nasnet-large/NASNet-large-no-top.h5'\n\n# Load weights locally\nbase_model.load_weights(weights_path_NASNetLarge)\n\n# Set the convolutional base to be non-trainable (freeze the weights)\nbase_model.trainable = False\n# summarize the base model architecture\nbase_model.summary()\nprint(\"****************************************************************\")\n# Input layer\ninput_layer = Input(shape=input_shape_nasnet)\n \n\n# Pass through NASNetLarge base model\noutput = base_model(input_layer)\n\n# Add custom convolutional layers with reduced downsampling\nconv_1 = Conv2D(32, kernel_size=(3, 3), activation=\"relu\")(output)\nmaxp_1 = MaxPooling2D(pool_size=(1, 1))(conv_1)\n\nconv_2 = Conv2D(64, kernel_size=(3, 3), activation=\"relu\")(maxp_1)\nmaxp_2 = MaxPooling2D(pool_size=(1, 1))(conv_2)\n\nconv_3 = Conv2D(128, kernel_size=(3, 3), activation=\"relu\")(maxp_2)\nmaxp_3 = MaxPooling2D(pool_size=(1, 1))(conv_3)\n\nconv_4 = Conv2D(160, kernel_size=(1, 1), activation=\"relu\")(maxp_3)\n\n# Flatten and add custom dense layers\nflatten = Flatten()(conv_4)\ndense_1 = Dense(256, activation=\"relu\")(flatten)\ndropout_1 = Dropout(0.3)(dense_1)\n\n# Output layer for gender prediction\noutput_gender = Dense(1, activation='sigmoid', name='output_gender')(dropout_1)\n\n# Output layer for age prediction (using linear activation for regression)\noutput_age = Dense(1, activation='linear', name='output_age')(dropout_1)\n\n# Create the NASNetLarge model with custom layers\nnasnet_model = Model(inputs=input_layer, outputs=[output_gender, output_age])\n\n# Print a summary of the model architecture\nnasnet_model.summary()\n\n# Compile the model\nnasnet_model.compile(optimizer=Adam(),\n                            loss=['binary_crossentropy', 'mean_absolute_error'],\n                            metrics=['accuracy'])\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot the nasnet model  \nplot_model(nasnet_model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the Xception model  \nhistory7 = nasnet_model.fit(x=X_train, y=[y_gender_train, y_age_train], batch_size=32, epochs=10, validation_data=(X_val, [y_gender_val, y_age_val]))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Plot the Results\n# plot results for gender\nacc = history7.history['output_gender_accuracy']\nval_acc = history7.history['val_output_gender_accuracy']\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'b', label='Training Accuracy')\nplt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\nplt.title('Accuracy Graph')\nplt.legend()\nplt.figure()\n\nprint(\"-----------------------------------------------------------------------------------------\")\n# plot results for gender\nloss = history7.history['output_gender_loss']\nval_loss = history7.history['val_output_gender_loss']\n\nplt.plot(epochs, loss, 'b', label='Training Loss')\nplt.plot(epochs, val_loss, 'r', label='Validation Loss')\nplt.title('Loss Graph')\nplt.legend()\nplt.show()\n\nprint(\"-----------------------------------------------------------------------------------------\")\n# plot results for age\nloss = history7.history['output_age_loss']\nval_loss = history7.history['val_output_age_loss']\nepochs = range(len(loss))\n\nplt.plot(epochs, loss, 'b', label='Training Loss')\nplt.plot(epochs, val_loss, 'r', label='Validation Loss')\nplt.title('Loss Graph')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#For model EfficientNetB7\n\n# Assuming your input_shape is (600, 600, 3) for EfficientNetB7\ninput_shape_efficientnet = (600, 600, 3)\n\n# Load the EfficientNetB7 model pre-trained on ImageNet data\nbase_model = EfficientNetB7(weights=None, include_top=False, input_shape=input_shape_efficientnet)\n\n# Specify the local path to the EfficientNetB7 weights file\nweights_path_EfficientNetB7 = '../input/efficientnetb7/efficientnetb7_notop.h5'\n\n# Load weights locally\nbase_model.load_weights(weights_path_EfficientNetB7)\n\n\n# Set the convolutional base to be non-trainable (freeze the weights)\nbase_model.trainable = False\n# summarize the base model architecture\nbase_model.summary()\nprint(\"****************************************************************\")\n# Input layer\ninput_layer = Input(shape=input_shape_efficientnet)\n \n\n# Pass through EfficientNetB7 base model\noutput = base_model(input_layer)\n\n# Add custom convolutional layers with reduced downsampling\nconv_1 = Conv2D(32, kernel_size=(3, 3), activation=\"relu\")(output)\nmaxp_1 = MaxPooling2D(pool_size=(1, 1))(conv_1)\n\nconv_2 = Conv2D(64, kernel_size=(3, 3), activation=\"relu\")(maxp_1)\nmaxp_2 = MaxPooling2D(pool_size=(1, 1))(conv_2)\n\nconv_3 = Conv2D(128, kernel_size=(3, 3), activation=\"relu\")(maxp_2)\nmaxp_3 = MaxPooling2D(pool_size=(1, 1))(conv_3)\n\nconv_4 = Conv2D(160, kernel_size=(1, 1), activation=\"relu\")(maxp_3)\n\n# Flatten and add custom dense layers\nflatten = Flatten()(conv_4)\ndense_1 = Dense(256, activation=\"relu\")(flatten)\ndropout_1 = Dropout(0.3)(dense_1)\n\n# Output layer for gender prediction\noutput_gender = Dense(1, activation='sigmoid', name='output_gender')(dropout_1)\n\n# Output layer for age prediction (using linear activation for regression)\noutput_age = Dense(1, activation='linear', name='output_age')(dropout_1)\n\n# Create the EfficientNetB7 model with custom layers\nefficientnet_model = Model(inputs=input_layer, outputs=[output_gender, output_age])\n\n# Print a summary of the model architecture\nefficientnet_model.summary()\n\n# Compile the model\nefficientnet_model.compile(optimizer=Adam(),\n                                  loss=['binary_crossentropy', 'mean_absolute_error'],\n                                  metrics=['accuracy'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot the efficientnet model  \nplot_model(efficientnet_model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the Xception model  \nhistory8 = efficientnet_model.fit(x=X_train, y=[y_gender_train, y_age_train], batch_size=32, epochs=10, validation_data=(X_val, [y_gender_val, y_age_val]))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Plot the Results\n# plot results for gender\nacc = history8.history['output_gender_accuracy']\nval_acc = history8.history['val_output_gender_accuracy']\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'b', label='Training Accuracy')\nplt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\nplt.title('Accuracy Graph')\nplt.legend()\nplt.figure()\n\nprint(\"-----------------------------------------------------------------------------------------\")\n# plot results for gender\nloss = history8.history['output_gender_loss']\nval_loss = history8.history['val_output_gender_loss']\n\nplt.plot(epochs, loss, 'b', label='Training Loss')\nplt.plot(epochs, val_loss, 'r', label='Validation Loss')\nplt.title('Loss Graph')\nplt.legend()\nplt.show()\n\nprint(\"-----------------------------------------------------------------------------------------\")\n# plot results for age\nloss = history8.history['output_age_loss']\nval_loss = history8.history['val_output_age_loss']\nepochs = range(len(loss))\n\nplt.plot(epochs, loss, 'b', label='Training Loss')\nplt.plot(epochs, val_loss, 'r', label='Validation Loss')\nplt.title('Loss Graph')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create the model EfficientNetV2L\n\n# Assuming your input_shape is (600, 600, 3) for EfficientNetV2L\ninput_shape_efficientnet = (600, 600, 3)\n\n# Load the EfficientNetV2L model pre-trained on ImageNet data\nbase_model = EfficientNetV2L(weights=None, include_top=False, input_shape=input_shape_efficientnet)\n\n# Specify the local path to the EfficientNetB7 weights file\nweights_path_EfficientNetV2L = '../input/efficientnetv2-l/efficientnetv2-l_notop.h5'\n\n# Load weights locally\nbase_model.load_weights(weights_path_EfficientNetV2L)\n\n# Set the convolutional base to be non-trainable (freeze the weights)\nbase_model.trainable = False\n# summarize the base model architecture\nbase_model.summary()\nprint(\"****************************************************************\")\n# Input layer\ninput_layer = Input(shape=input_shape_efficientnet)\n \n# Pass through EfficientNetV2L base model\noutput = base_model(input_layer)\n\n# Add custom convolutional layers with reduced downsampling\nconv_1 = Conv2D(32, kernel_size=(3, 3), activation=\"relu\")(output)\nmaxp_1 = MaxPooling2D(pool_size=(1, 1))(conv_1)\n\nconv_2 = Conv2D(64, kernel_size=(3, 3), activation=\"relu\")(maxp_1)\nmaxp_2 = MaxPooling2D(pool_size=(1, 1))(conv_2)\n\nconv_3 = Conv2D(128, kernel_size=(3, 3), activation=\"relu\")(maxp_2)\nmaxp_3 = MaxPooling2D(pool_size=(1, 1))(conv_3)\n\nconv_4 = Conv2D(160, kernel_size=(1, 1), activation=\"relu\")(maxp_3)\n\n# Flatten and add custom dense layers\nflatten = Flatten()(conv_4)\ndense_1 = Dense(256, activation=\"relu\")(flatten)\ndropout_1 = Dropout(0.3)(dense_1)\n\n# Output layer for gender prediction\noutput_gender = Dense(1, activation='sigmoid', name='output_gender')(dropout_1)\n\n# Output layer for age prediction (using linear activation for regression)\noutput_age = Dense(1, activation='linear', name='output_age')(dropout_1)\n\n# Create the EfficientNetV2L model with custom layers\nEfficientNetV2L_model = Model(inputs=input_layer, outputs=[output_gender, output_age])\n\n# Print a summary of the model architecture\nEfficientNetV2L_model.summary()\n\n# Compile the model\nEfficientNetV2L_model.compile(optimizer=Adam(),\n                                  loss=['binary_crossentropy', 'mean_absolute_error'],\n                                  metrics=['accuracy'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot the EfficientNetV2L model  \nplot_model(EfficientNetV2L_model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the EfficientNetV2L model  \nhistory9 = EfficientNetV2L_model.fit(x=X_train, y=[y_gender_train, y_age_train], batch_size=32, epochs=10, validation_data=(X_val, [y_gender_val, y_age_val]))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Plot the Results\n# plot results for gender\nacc = history9.history['output_gender_accuracy']\nval_acc = history9.history['val_output_gender_accuracy']\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'b', label='Training Accuracy')\nplt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\nplt.title('Accuracy Graph')\nplt.legend()\nplt.figure()\n\nprint(\"-----------------------------------------------------------------------------------------\")\n# plot results for gender\nloss = history9.history['output_gender_loss']\nval_loss = history9.history['val_output_gender_loss']\n\nplt.plot(epochs, loss, 'b', label='Training Loss')\nplt.plot(epochs, val_loss, 'r', label='Validation Loss')\nplt.title('Loss Graph')\nplt.legend()\nplt.show()\n\nprint(\"-----------------------------------------------------------------------------------------\")\n# plot results for age\nloss = history9.history['output_age_loss']\nval_loss = history9.history['val_output_age_loss']\nepochs = range(len(loss))\n\nplt.plot(epochs, loss, 'b', label='Training Loss')\nplt.plot(epochs, val_loss, 'r', label='Validation Loss')\nplt.title('Loss Graph')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create model ConvNeXtXLarge\n\n# Define the input shape\ninput_shape_ConvNeXtXLarge = (224, 224, 3)  # Adjust the input shape as needed\n\n# Load the ConvNeXtXLarge model with pre-trained ImageNet weights\nbase_model = ConvNeXtXLarge(weights=None, input_shape=input_shape, include_top=False)\n# Specify the local path to the ConvNeXtXLarge weights file\nweights_path_ConvNeXtXLarge = '../input/convnext-xlarge/convnext_xlarge_notop.h5'\n# Load weights locally\nbase_model.load_weights(weights_path_ConvNeXtXLarge)\n\n# Set the convolutional base to be non-trainable (freeze the weights)\nbase_model.trainable = False\n# summarize the base model architecture\nbase_model.summary()\nprint(\"****************************************************************\")\n# Input layer\ninput_layer = Input(shape=input_shape_ConvNeXtXLarge)\n \n# Pass through ConvNeXtXLarge base model\noutput = base_model(input_layer)\n\n# Add custom convolutional layers with reduced downsampling\nconv_1 = Conv2D(32, kernel_size=(3, 3), activation=\"relu\")(output)\nmaxp_1 = MaxPooling2D(pool_size=(1, 1))(conv_1)\n\nconv_2 = Conv2D(64, kernel_size=(3, 3), activation=\"relu\")(maxp_1)\nmaxp_2 = MaxPooling2D(pool_size=(1, 1))(conv_2)\n\nconv_3 = Conv2D(128, kernel_size=(3, 3), activation=\"relu\")(maxp_2)\nmaxp_3 = MaxPooling2D(pool_size=(1, 1))(conv_3)\n\nconv_4 = Conv2D(160, kernel_size=(1, 1), activation=\"relu\")(maxp_3)\n\n# Flatten and add custom dense layers\nflatten = Flatten()(conv_4)\ndense_1 = Dense(256, activation=\"relu\")(flatten)\ndropout_1 = Dropout(0.3)(dense_1)\n\n# Output layer for classification\noutput_classification = Dense(1000, activation='softmax', name='output_classification')(dropout_1)\n\n# Create the ConvNeXtXLarge model with custom layers\nconvnext_model = Model(inputs=input_layer, outputs=output_classification)\n\n# Print a summary of the model architecture\nconvnext_model.summary()\n\n# Compile the model\nconvnext_model.compile(optimizer=Adam(),\n                              loss='categorical_crossentropy',\n                              metrics=['accuracy'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot the convnext model  \nplot_model(convnext_model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the convnext model  \nhistory10 = convnext_model.fit(x=X_train, y=[y_gender_train, y_age_train], batch_size=32, epochs=32, validation_data=(X_val, [y_gender_val, y_age_val]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Plot the Results\n# plot results for gender\nacc = history10.history['output_gender_accuracy']\nval_acc = history10.history['val_output_gender_accuracy']\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'b', label='Training Accuracy')\nplt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\nplt.title('Accuracy Graph')\nplt.legend()\nplt.figure()\n\nprint(\"-----------------------------------------------------------------------------------------\")\n# plot results for gender\nloss = history10.history['output_gender_loss']\nval_loss = history10.history['val_output_gender_loss']\n\nplt.plot(epochs, loss, 'b', label='Training Loss')\nplt.plot(epochs, val_loss, 'r', label='Validation Loss')\nplt.title('Loss Graph')\nplt.legend()\nplt.show()\n\nprint(\"-----------------------------------------------------------------------------------------\")\n# plot results for age\nloss = history10.history['output_age_loss']\nval_loss = history10.history['val_output_age_loss']\nepochs = range(len(loss))\n\nplt.plot(epochs, loss, 'b', label='Training Loss')\nplt.plot(epochs, val_loss, 'r', label='Validation Loss')\nplt.title('Loss Graph')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}